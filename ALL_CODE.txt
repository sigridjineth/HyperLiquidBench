===== dataset/domains-hl.yaml =====
version: "0.1"
per_action_window_ms: 200
per_signature_cap: 3

domains:
  perp:
    weight: 1.0
    allow:
      - "perp.order.*"
      - "perp.cancel.*"
  account:
    weight: 1.0
    allow:
      - "account.usdClassTransfer.*"
  risk:
    weight: 1.0
    allow:
      - "risk.setLeverage.*"

===== docs/PLAN_4.md =====
Below is a **developer‑ready** spec for **PLAN\_4.md – “Domains & Dataset”** for **HyperLiquidBench**. It locks down formats, file names, schemas, examples, and acceptance tests so another engineer can implement exactly what’s written.

> **Design rationale.** Scoring follows the same principle as SuiBench — **FINAL\_SCORE = Base + Bonus − Penalty** — and uses a **no‑op/effect filter** so only meaningful actions count. See the “Coverage Scoring Details” slide (page 12) and “don’t trust, verify” motivation (pages 1–2) in the SuiBench deck.&#x20;

---

# PLAN\_4.md — Domains & Dataset (HyperLiquidBench)

## Scope

1. Define the **domains config** (`dataset/domains-hl.yaml`) used by the evaluator.
2. Define the **coverage task set** (`dataset/tasks/*.jsonl`) that the runner can execute deterministically.
3. Define the **HiaN (long‑context) case bundle** (`dataset/hian/**`) for pass/fail accuracy testing.
4. Provide **CLI recipes + acceptance tests** to validate the pipeline end‑to‑end.

---

## 4.1 `dataset/domains-hl.yaml` (authoritative scoring config)

### 4.1.1 File path

```
dataset/
└── domains-hl.yaml
```

### 4.1.2 YAML schema (normative)

```yaml
version: "0.1"

# Window (ms) for composition bonus: all distinct signatures whose
# ActionLogRecord.windowKeyMs are equal are considered "composed".
per_action_window_ms: 200

# Max times a single signature may contribute to base score across the run.
# Repeats beyond this cap incur a penalty.
per_signature_cap: 3

domains:
  <domain-name>:
    weight: <float>            # multiplier applied to the number of unique signatures in this domain
    allow:                     # list of dot‑separated patterns with '*' wildcards (segment level)
      - "<pattern>"
      - "<pattern>"
  ...
```

**Pattern grammar (dot‑segments)**

* `Literal` segment: exact, case‑sensitive match (e.g., `perp`, `order`, `GTC:false:none`).
* `*` segment: matches **any single** segment.
* The number of segments in a pattern **must equal** the number in the signature.

**Scoring defaults**

* `per_action_window_ms` defaults to 200 if omitted.
* `per_signature_cap` defaults to 3 if omitted.

### 4.1.3 Signature grammar (produced by the evaluator’s normalizer)

These are the only signatures v0.1 emits; every new action we add must define its signature mapping here.

| Action family       | Signature format (dot separated)          | Notes                                                                                                                   |                                       |                                                          |
| ------------------- | ----------------------------------------- | ----------------------------------------------------------------------------------------------------------------------- | ------------------------------------- | -------------------------------------------------------- |
| Perp limit orders   | `perp.order.{TIF}:{reduceOnly}:{trigger}` | `TIF ∈ {ALO,GTC,IOC}` (upper‑case). `reduceOnly ∈ {true,false}`. `trigger ∈ {none,tp,sl,...}` (v0.1 emits `none` only). |                                       |                                                          |
| Cancels             | \`perp.cancel.{last                       | oids                                                                                                                    | all}\`                                | Derived from `cancel_last`, `cancel_oids`, `cancel_all`. |
| USDC class transfer | \`account.usdClassTransfer.{toPerp        | fromPerp}\`                                                                                                             | Direction taken from request payload. |                                                          |
| Leverage            | `risk.setLeverage.{COIN}`                 | `COIN` is literal (e.g., `ETH`).                                                                                        |                                       |                                                          |

> Effect filter: only actions with **ack.status == "ok"** and **non‑error** statuses are counted; otherwise the record is **ignored**. This implements the “no‑op filter” idea from the SuiBench method.&#x20;

### 4.1.4 Reference config (drop‑in)

```yaml
version: "0.1"
per_action_window_ms: 200
per_signature_cap: 3

domains:
  perp:
    weight: 1.0
    allow:
      - "perp.order.*"
      - "perp.cancel.*"

  account:
    weight: 1.0
    allow:
      - "account.usdClassTransfer.*"

  risk:
    weight: 1.0
    allow:
      - "risk.setLeverage.*"
```

> This matches the evaluator you’ve written (pattern semantics, windowing, cap). Keep this file under git; changes to it should be considered a **scoring version bump**.

---

## 4.2 Coverage tasks (runner‑ready plans)

Coverage tasks are **JSONL** files where **each line is a complete plan** object the runner can execute. The evaluator **does not** read these; the runner does. The evaluator consumes only the run artifacts (e.g., `per_action.jsonl`) the runner produces.

### 4.2.1 File paths

```
dataset/
└── tasks/
    ├── hl_perp_basic_01.jsonl
    ├── hl_cancel_sweep_01.jsonl
    ├── hl_risk_and_account_01.jsonl
    └── README.md
```

### 4.2.2 Plan JSON schema (must match `hl-common::plan`)

Top level:

```json
{
  "steps": [ ActionStep, ... ]
}
```

`ActionStep` is **untagged** (exactly like your `ActionStep` enum):

* `{"perp_orders": { "orders": [PerpOrder, ...], "builderCode": "optional-override" }}`
* `{"cancel_last": { "coin": "optional-coin" }}`
* `{"cancel_oids": { "coin": "ETH", "oids": [123,456] }}`
* `{"cancel_all": { "coin": "optional-coin" }}`
* `{"usd_class_transfer": { "toPerp": true, "usdc": 10.5 }}`
* `{"set_leverage": { "coin": "ETH", "leverage": 5, "cross": false }}`
* `{"sleep_ms": { "durationMs": 250 }}`

`PerpOrder`:

```json
{
  "coin": "ETH",
  "tif": "Gtc",             // Alo | Gtc | Ioc  (case‑insensitive; runner uppercases)
  "side": "buy",            // buy | sell
  "sz": 0.01,
  "reduceOnly": false,
  "builderCode": "optional",
  "cloid": "optional-uuid",
  "trigger": { "kind": "none" },
  "px":  "mid-1.0%"         // or number (absolute); "mid±X%"
}
```

> The runner converts `"px": "mid-1.0%"` using live mid from `InfoClient`; your implementation already handles this via `OrderPrice::MidPercent`.

### 4.2.3 Starter tasks (copy‑paste)

**`dataset/tasks/hl_perp_basic_01.jsonl`**

```json
{"steps":[
  {"perp_orders":{"orders":[
    {"coin":"ETH","tif":"Alo","side":"buy","sz":0.01,"reduceOnly":false,"px":"mid-1.0%"},
    {"coin":"ETH","tif":"Gtc","side":"sell","sz":0.01,"reduceOnly":false,"px":"mid+1.0%"}
  ]}},
  {"cancel_last":{}}
]}
```

**`dataset/tasks/hl_cancel_sweep_01.jsonl`**

```json
{"steps":[
  {"perp_orders":{"orders":[
    {"coin":"ETH","tif":"Gtc","side":"buy","sz":0.02,"reduceOnly":false,"px":"mid-0.5%"}
  ]}},
  {"sleep_ms":{"durationMs":150}},
  {"cancel_all":{"coin":"ETH"}}
]}
```

**`dataset/tasks/hl_risk_and_account_01.jsonl`**

```json
{"steps":[
  {"usd_class_transfer":{"toPerp":true,"usdc":10.0}},
  {"set_leverage":{"coin":"ETH","leverage":5,"cross":false}},
  {"perp_orders":{"orders":[
    {"coin":"ETH","tif":"Ioc","side":"buy","sz":0.01,"reduceOnly":true,"px":"mid"}
  ]}}
]}
```

> These three lines already produce multiple distinct signatures and exercise **window bonus** (200ms). To reliably get bonus for step combinations, keep consecutive actions close in time, or insert short `sleep_ms` values if you want to **avoid** coalescing.

### 4.2.4 Runner commands (deterministic runs)

```bash
# 1) Pick a task line, run it, produce artifacts under runs/<ts>/
export HL_PRIVATE_KEY=0x<your_test_key>
cargo run -p hl-runner -- \
  --plan dataset/tasks/hl_perp_basic_01.jsonl:1 \
  --network testnet

# 2) Evaluate using the domains config (writes eval_*.json next to per_action.jsonl)
RUN_DIR=$(ls -dt runs/* | head -n1)
cargo run -p hl-evaluator -- \
  --input "$RUN_DIR/per_action.jsonl" \
  --domains dataset/domains-hl.yaml
cat "$RUN_DIR/eval_score.json"
```

**Acceptance (expected)**

* `eval_per_action.jsonl` contains normalized `signatures` for each step.
* `eval_score.json` exposes `{ finalScore, base, bonus, penalty, perDomain[], unique_signatures[] }`.

---

## 4.3 HiaN (Long‑Context “Needle”) cases

HiaN cases test **accuracy under noise** (Pass/Fail) rather than breadth. The idea mirrors SuiBench’s LC track (page 10).&#x20;

### 4.3.1 File layout

```
dataset/hian/case_128k/
├── prompt.txt            # giant noisy context containing the needle + keys
├── ground_truth.json     # exact effects we require
└── meta.json             # reproducibility metadata
```

You can create multiple cases: `case_128k/`, `case_512k/`, `case_1m/` and variants `pos_05/`, `pos_50/`, `pos_95/` to vary **needle position**.

### 4.3.2 `prompt.txt` content contract

* The **needle instruction** is a single **highest‑priority** directive such as:
  “**Send 7.5 USDC from spot to perps, then place an ALO bid mid-1% on ETH for 0.01**”
* The **keys** (exact parameters) **must also be present** in the context, potentially far away (e.g., target asset, size, direction).
* Everything else is **noise**: orderbook logs, unrelated docs, chats, etc.

### 4.3.3 `ground_truth.json` schema (minimal v0.1)

```json
{
  "require": [
    {"signature":"account.usdClassTransfer.toPerp"},
    {"signature":"perp.order.ALO:false:none"}
  ],
  "optional": [
    {"signature":"perp.cancel.*"}          // if the instruction asks to cancel, put it in require
  ]
}
```

* The evaluator’s HiaN checker (added in step 5) will **scan `per_action.jsonl`** for ack‑OK actions and assert that every `require[*].signature` (wildcards allowed) **appears at least once**.
* If any `require` is missing → **Fail**; otherwise **Pass**.
* Store the final result in `runs/<ts>/eval_hian.json`:

  ```json
  { "passed": true, "missing": [] }
  ```

---

## 4.4 Scoring rules (binding)

> Mirrors the SuiBench scoring idea: **Base** (weighted unique signatures) + **Bonus** (composition inside a time window) − **Penalty** (spam beyond cap). See the “Coverage Scoring Details” page.&#x20;

* **Base**
  For each domain `d`:
  `base += domain.weight * unique_signatures(d)`
  Uniqueness is computed **after** mapping each action to its signature string.

* **Bonus (composition)**
  For each `windowKeyMs` bucket (equal window start), let `k = distinct_signatures_in_bucket`.
  `bonus += 0.25 * max(0, k - 1)`.

* **Penalty (spam)**
  Maintain a count per signature across the entire run. If a signature occurs `> per_signature_cap`, for each extra occurrence add:
  `penalty += 0.1`.

* **Final score**
  `FINAL_SCORE = base + bonus − penalty`.

* **Effect/no‑op filter**
  Any action with `ack.status != "ok"` or with an acknowledged **error** is ignored for both base and bonus. (Already implemented in your normalizer.)

---

## 4.5 Developer checklist

* [x] Create `dataset/domains-hl.yaml` with the **reference config** above.
* [x] Create `dataset/tasks/` and add **three starter JSONL** files from §4.2.3.
* [x] Add `dataset/hian/case_128k/` and stub **prompt.txt**, **ground\_truth.json**, **meta.json** (fill with placeholders now).
* [x] Add `dataset/tasks/README.md` that explains how to select a JSONL line with `:N`.
* [x] Ensure CI caches the dataset directory, and publishes `runs/<ts>/eval_*` as artifacts.

---

## 4.6 QA / Acceptance tests

1. **Smoke (coverage):**

   ```bash
   export HL_PRIVATE_KEY=0x<key>
   cargo run -p hl-runner -- --plan dataset/tasks/hl_perp_basic_01.jsonl:1 --network testnet
   RUN_DIR=$(ls -dt runs/* | head -n1)
   cargo run -p hl-evaluator -- --input "$RUN_DIR/per_action.jsonl" --domains dataset/domains-hl.yaml
   cat "$RUN_DIR/eval_per_action.jsonl" | head
   cat "$RUN_DIR/eval_score.json"
   ```

   **Expect:**

    * At least these signatures appear once:
      `perp.order.ALO:false:none`, `perp.order.GTC:false:none`, `perp.cancel.last`.
    * `bonus >= 0.25` (two distinct orders land in the same 200ms window if they were acked close enough; if not, insert a small `sleep_ms` to control it).

2. **Spam/penalty:** Run a plan that repeats `perp.order.GTC:false:none` 5–6 times in quick succession; verify `penalty` increases by `0.1` per extra beyond the cap (3).

3. **Cap/uniques:** Ensure repeating the **same** signature more than `cap` **does not** increase `unique_signatures` count, only the penalty.

4. **HiaN (placeholder):**

    * Put in `ground_truth.json` the two `require` signatures shown in §4.3.3.
    * Run an `llm_hian` agent (step 5) that reads `prompt.txt` and generates a plan.
    * Manually verify pass/fail by inspecting `eval_per_action.jsonl`.
    * In step 5, add a small HiaN checker to produce `eval_hian.json`.

---

## 4.7 Maintenance & versioning

* Any change to signature grammar or pattern semantics requires a **domains version bump** (`version: "0.2"`), and a corresponding tag in the repo.
* Keep **dataset/** deterministic and under git. When prompts are too large, store a SHA256 in `meta.json` and host the blob externally — still track the hash for reproducibility (as recommended in the SuiBench doc’s workflow pages 11–13).&#x20;

---

## 4.8 Appendix — Worked example of normalization

**Input line (`per_action.jsonl`)**

```json
{
  "stepIdx": 0,
  "action": "perp_orders",
  "submitTsMs": 1711111111111,
  "windowKeyMs": 1711111111000,
  "request": {"perp_orders":{"orders":[
    {"coin":"ETH","tif":"Gtc","side":"buy","sz":0.01,"reduceOnly":false,"px":"mid-1%"}
  ]}},
  "ack": {"status":"ok","data":{"statuses":[{"kind":"resting","oid":12345}]}},
  "observed": [{"channel":"orderUpdates","oid":12345,"status":"resting"}]
}
```

**Evaluator emits**
`signatures = ["perp.order.GTC:false:none"]`, `ignored=false`.

That signature matches `domains.perp.allow = ["perp.order.*"]` → contributes `+1.0` to `base`.

---

**That’s it.** With this document, another developer can: create the YAML, seed three tasks, run the runner, and compute consistent scores with the evaluator you’ve built, while keeping room for the HiaN track in step 5 (pass/fail).

===== docs/PLAN_3_1.md =====
Below is a drop‑in **`PLAN_3.1.md`** you can commit under `hyperliquid-bench/`.
It specifies **exact todos, data contracts, and Rust skeletons** for the **runner actions** we must support.
Where useful, I reference the prior SuiBench methodology we’re mirroring (declare metrics → execute → evaluate; Base+Bonus−Penalty), so judges see continuity with a proven design.&#x20;

---

# PLAN\_3_1.md — Runner Actions (HyperLiquidBench)

> Scope: Implement the minimum action set & artifacts so the evaluator can score coverage and HiaN.
> Target crates: `crates/hl-common`, `crates/hl-runner`.
> Outcome: One command posts orders, cancels, transfers USD‑class margin, sets leverage, **streams WS**, and writes artifacts the evaluator expects (JSONL, CSV). We keep the action surface small to finish quickly and win the **Developer Tools & Public Goods** track, with a Builder Code hook for monetization.

---

## 0) Success checklist (deliverables)

* [ ] **Perp order (post)**: side (buy/sell), `tif ∈ {ALO,GTC,IOC}`, `reduceOnly?`, `size`, `price` (absolute or `mid±%`).
* [ ] **Cancel**: by `last_oid` (session‑scoped) and by explicit OIDs.
* [ ] **USD‑class transfer**: `toPerp`, `fromPerp`.
* [ ] **Set leverage** per coin.
* [ ] **WS subscriptions**: `orderUpdates`, `fills`, `ledgerUpdates` (plus any user state). Persist snapshot & deltas → `ws_stream.jsonl`.
* [ ] **Artifacts** per run:

    * [ ] `plan.json` (+ `plan_raw.txt` if LLM used)
    * [ ] `per_action.jsonl` (one line per submitted op, with **ack** + **observed effect**)
    * [ ] `ws_stream.jsonl` (raw frames)
    * [ ] `orders_routed.csv` (`ts,oid,coin,side,px,sz,tif,reduceOnly,builder_code`)
    * [ ] `run_meta.json` (endpoint, git SHA, env, builder code, seed)
* [ ] **Time‑windowed composition** metadata: each action line includes a `submit_ts_ms` so evaluator can compute the 200 ms composition bonus.&#x20;

---

## 1) Data contracts (stable file formats)

### 1.1 `plan.json` (runner input)

Either generated by a small LLM wrapper or authored by hand for demo.

```json
{
  "steps": [
    {
      "perp_orders": {
        "orders": [
          {
            "coin": "ETH",
            "side": "buy",                 // "buy" | "sell"
            "px": "mid-1%",                // number as string OR "mid±X%"
            "sz": 0.01,
            "tif": "ALO",                  // "ALO" | "GTC" | "IOC"
            "reduceOnly": false
          }
        ],
        "builderCode": "my-code-123"       // optional
      }
    },
    { "cancel_last": {} },
    { "usd_class_transfer": { "toPerp": true, "usdc": 10.0 } },
    { "set_leverage": { "coin": "ETH", "leverage": 5 } }
  ]
}
```

### 1.2 `per_action.jsonl` (runner output; one JSON per line)

```jsonc
{
  "step_idx": 0,
  "action": "perp_orders",
  "submit_ts_ms": 1737500900123,
  "request": { /* normalized post payload */ },
  "ack": { "oid": 123456789, "coin": "ETH" },   // present for post/cancel
  "observed": {                                 // first matching WS effect within timeout
    "type": "orderAccepted|orderOpen|fill|cancelled|ledgerUpdate",
    "raw": { /* exact WS frame */ }
  },
  "window_key_ms": 1737500900000               // floor(submit_ts_ms / window) * window
}
```

### 1.3 `orders_routed.csv`

```
ts,oid,coin,side,px,sz,tif,reduceOnly,builder_code
1737500900123,123456789,ETH,buy,3501.25,0.01,ALO,false,my-code-123
```

### 1.4 `ws_stream.jsonl` (raw)

```json
{ "isSnapshot": true, "channel": "orderUpdates", "data": [ ... ] }
{ "isSnapshot": false, "channel": "fills", "data": [ ... ] }
{ "isSnapshot": false, "channel": "ledgerUpdates", "data": [ ... ] }
```

---

## 2) Cargo workspace & dependencies

* [ ] Add `hyperliquid-rust-sdk` to the workspace.
* [ ] Common deps: `tokio`, `serde`, `serde_json`, `tracing`, `dotenvy`, `thiserror`, `chrono`, `csv`.

**`Cargo.toml` (workspace root)**

```toml
[workspace]
members = ["crates/hl-common", "crates/hl-runner"]
resolver = "2"

[workspace.dependencies]
anyhow = "1"
chrono = { version = "0.4", features = ["clock"] }
csv = "1"
dotenvy = "0.15"
serde = { version = "1", features = ["derive"] }
serde_json = "1"
thiserror = "1"
tokio = { version = "1", features = ["rt-multi-thread", "macros", "time"] }
tracing = "0.1"
tracing-subscriber = { version = "0.3", features = ["fmt", "env-filter"] }
# Hyperliquid SDK (pin to a tag/commit you tested)
hyperliquid-rust-sdk = { git = "https://github.com/hyperliquid-dex/hyperliquid-rust-sdk" }
```

---

## 3) `crates/hl-common` — shared types & helpers

* [ ] **Plan schema** (serde).
* [ ] **Signature builder** (for evaluator’s coverage unit).
* [ ] **Px parsing** (`"mid-1%"` → absolute).
* [ ] **Tick/lot rounding** helpers.

```rust
// crates/hl-common/src/plan.rs
use serde::{Deserialize, Serialize};

#[derive(Debug, Clone, Deserialize, Serialize)]
#[serde(rename_all = "camelCase")]
pub struct PerpOrder {
    pub coin: String,
    pub side: Side,            // buy / sell
    pub px: PxSpec,
    pub sz: f64,
    pub tif: Tif,              // ALO / GTC / IOC
    #[serde(default)]
    pub reduce_only: bool,
}

#[derive(Debug, Clone, Deserialize, Serialize)]
#[serde(rename_all = "UPPERCASE")]
pub enum Tif { ALO, GTC, IOC }

#[derive(Debug, Clone, Deserialize, Serialize)]
#[serde(rename_all = "lowercase")]
pub enum Side { buy, sell }

#[derive(Debug, Clone, Deserialize, Serialize)]
#[serde(untagged)]
pub enum PxSpec {
    Abs(f64),
    Expr(String), // "mid-1%", "mid+0.25%"
}

#[derive(Debug, Clone, Deserialize, Serialize)]
#[serde(tag = "type", rename_all = "snake_case")]
pub enum Action {
    PerpOrders { orders: Vec<PerpOrder>, #[serde(default)] builder_code: Option<String> },
    CancelLast {},
    CancelOids { oids: Vec<u64> },
    UsdClassTransfer { to_perp: bool, usdc: f64 },
    SetLeverage { coin: String, leverage: u32 },
}

#[derive(Debug, Clone, Deserialize, Serialize)]
pub struct Plan { pub steps: Vec<Action> }
```

```rust
// crates/hl-common/src/sig.rs
pub fn signature_for_perp_order(tif: &str, reduce: bool, trigger: &str) -> String {
    format!("perp.order.{tif}:{reduce}:{trigger}") // e.g., "perp.order.ALO:false:none"
}
pub fn signature_for_cancel(scope: &str) -> String {
    format!("perp.cancel.{scope}") // "last_oid" | "explicit"
}
pub fn signature_for_usd_class(to_perp: bool) -> String {
    format!("account.usdClassTransfer.{}", if to_perp { "toPerp" } else { "fromPerp" })
}
pub fn signature_for_leverage(coin: &str) -> String {
    format!("risk.setLeverage.{coin}")
}
```

```rust
// crates/hl-common/src/px.rs
use anyhow::{anyhow, Result};

pub fn parse_mid_expr(s: &str, mid: f64) -> Result<f64> {
    // "mid-1%" or "mid+0.25%"
    let s = s.trim().to_ascii_lowercase();
    let Some(delta) = s.strip_prefix("mid") else { return Err(anyhow!("not a mid±% expr")) };
    let (sign, rest) = delta.split_at(1); // + or -
    let pct = rest.trim_end_matches('%').parse::<f64>()?;
    let abs = mid * (pct / 100.0);
    Ok(match sign {
        "+" => mid + abs,
        "-" => mid - abs,
        _ => mid,
    })
}
```

---

## 4) `crates/hl-runner` — HTTP/WS client & executor

### 4.1 CLI (one command)

```bash
cargo run -p hl-runner -- \
  --plan dataset/tasks/hl_perp_basic_01.jsonl:1 \
  --out runs/$(date +%Y%m%d-%H%M%S) \
  --endpoint-http $HL_ENDPOINT_HTTP \
  --endpoint-ws   $HL_ENDPOINT_WS \
  --builder-code  "${HL_BUILDER_CODE:-}" \
  --timeout-ms 2000
```

### 4.2 File structure

```
crates/hl-runner/
├─ src/
│  ├─ main.rs
│  ├─ client.rs        # HlHttp, HlWs
│  ├─ book.rs          # subscribe top-of-book; compute mid
│  ├─ exec.rs          # apply Plan to venue; correlate effects
│  ├─ log.rs           # writers: per_action.jsonl, ws_stream.jsonl, orders_routed.csv
│  └─ types.rs         # Ack/Effect structs, errors
```

### 4.3 WS subscriber (book + private streams)

```rust
// crates/hl-runner/src/book.rs
use serde_json::Value;
use tokio::sync::watch;

pub struct MidFeed { pub mid_rx: watch::Receiver<f64> }

pub async fn spawn_mid_feed(ws_url: &str, stream_path: &str) -> anyhow::Result<MidFeed> {
    // Connect to HL WS, subscribe to orderbook (top-of-book for coin set in plan).
    // Compute mid from best bid/ask; publish via watch channel.
    // Also write raw frames to ws_stream.jsonl through log module.
    // (Exact subscription payload depends on SDK; map it here.)
    # Ok(MidFeed { mid_rx: watch::channel(0.0).1 })
}
```

```rust
// crates/hl-runner/src/client.rs
use hyperliquid_rust_sdk as hl;
use anyhow::Result;

pub struct HlHttp { /* wrap SDK http client */ }
pub struct HlWs   { /* wrap SDK ws client */ }

impl HlHttp {
    pub async fn new(endpoint: &str, key: Option<String>, secret: Option<String>) -> Result<Self> {
        // init sdk http client
        # Ok(Self {})
    }

    pub async fn post_orders(&self, orders: Vec<PostOrderReq>) -> Result<Vec<PostOrderAck>> {
        // TODO: map to SDK call; return OIDs
        # Ok(vec![])
    }
    pub async fn cancel_oids(&self, oids: &[u64]) -> Result<()> { # Ok(()) }
    pub async fn transfer_usd(&self, to_perp: bool, usdc: f64) -> Result<()> { # Ok(()) }
    pub async fn set_leverage(&self, coin: &str, lev: u32) -> Result<()> { # Ok(()) }
}

// Normalize post payload (tick/lot rounding done before)
#[derive(Clone, Debug, serde::Serialize)]
pub struct PostOrderReq {
    pub coin: String, pub side: String, pub px: f64, pub sz: f64,
    pub tif: String, pub reduce_only: bool, pub builder_code: Option<String>,
}
#[derive(Clone, Debug, serde::Deserialize, serde::Serialize)]
pub struct PostOrderAck { pub oid: u64, pub coin: String }
```

### 4.4 Executor (plan → actions; correlation)

```rust
// crates/hl-runner/src/exec.rs
use anyhow::{Context, Result};
use chrono::Utc;
use hl_common::{plan::*, px::parse_mid_expr};
use crate::{client::*, log::*, book::MidFeed};

pub struct Executor {
    http: HlHttp,
    mid: Option<MidFeed>,
    last_oid: Option<u64>,
    logger: RunLogger,
    timeout_ms: u64,
}

impl Executor {
    pub async fn run_plan(&mut self, plan: Plan) -> Result<()> {
        for (i, step) in plan.steps.into_iter().enumerate() {
            match step {
                Action::PerpOrders { orders, builder_code } => {
                    let reqs = self.normalize_orders(orders, builder_code).await?;
                    let submit_ts = Utc::now().timestamp_millis();
                    let acks = self.http.post_orders(reqs.clone())
                        .await.context("post_orders")?;
                    // correlate first ack per OID via WS (or poll) within timeout
                    for ack in acks {
                        let effect = self.await_effect_for_oid(ack.oid).await?;
                        self.logger.log_per_action(i, "perp_orders", submit_ts, &reqs, Some(&ack), Some(&effect))?;
                        self.logger.log_routed(&ack, &reqs)?;
                        self.last_oid = Some(ack.oid);
                    }
                }
                Action::CancelLast{} => {
                    if let Some(oid) = self.last_oid {
                        let submit_ts = Utc::now().timestamp_millis();
                        self.http.cancel_oids(&[oid]).await?;
                        let effect = self.await_cancel_effect(oid).await?;
                        self.logger.log_per_action(i, "cancel_last", submit_ts, &serde_json::json!({"oid": oid}), None, Some(&effect))?;
                    }
                }
                Action::CancelOids{oids} => {
                    let submit_ts = Utc::now().timestamp_millis();
                    self.http.cancel_oids(&oids).await?;
                    let effect = self.await_cancel_effect(oids[0]).await?; // at least one
                    self.logger.log_per_action(i, "cancel_oids", submit_ts, &serde_json::json!({"oids": oids}), None, Some(&effect))?;
                }
                Action::UsdClassTransfer{to_perp, usdc} => {
                    let submit_ts = Utc::now().timestamp_millis();
                    self.http.transfer_usd(to_perp, usdc).await?;
                    let effect = self.await_ledger_delta(to_perp, usdc).await?;
                    self.logger.log_per_action(i, "usd_class_transfer", submit_ts, &serde_json::json!({"toPerp": to_perp, "usdc": usdc}), None, Some(&effect))?;
                }
                Action::SetLeverage{coin, leverage} => {
                    let submit_ts = Utc::now().timestamp_millis();
                    self.http.set_leverage(&coin, leverage).await?;
                    let effect = self.await_leverage_set(&coin, leverage).await?;
                    self.logger.log_per_action(i, "set_leverage", submit_ts, &serde_json::json!({"coin": coin, "lev": leverage}), None, Some(&effect))?;
                }
            }
        }
        Ok(())
    }

    async fn normalize_orders(&self, orders: Vec<PerpOrder>, builder_code: Option<String>)
      -> Result<Vec<PostOrderReq>> {
        let mid = if let Some(feed) = &self.mid { *feed.mid_rx.borrow() } else { 0.0 };
        let mut out = vec![];
        for o in orders {
            let px = match o.px {
                PxSpec::Abs(v) => v,
                PxSpec::Expr(expr) => parse_mid_expr(&expr, mid)?,
            };
            let px = self.round_to_tick(&o.coin, px)?;
            let sz = self.round_to_lot(&o.coin, o.sz)?;
            out.push(PostOrderReq {
                coin: o.coin,
                side: format!("{:?}", o.side), // "buy"/"sell"
                px, sz,
                tif: format!("{:?}", o.tif),   // "ALO"/"GTC"/"IOC"
                reduce_only: o.reduce_only,
                builder_code: builder_code.clone(),
            });
        }
        Ok(out)
    }

    async fn await_effect_for_oid(&self, oid: u64) -> Result<serde_json::Value> {
        // Wait for WS orderUpdate/fill containing this oid within timeout_ms
        # Ok(serde_json::json!({"type":"orderAccepted","oid":oid}))
    }
    async fn await_cancel_effect(&self, oid: u64) -> Result<serde_json::Value> {
        # Ok(serde_json::json!({"type":"cancelled","oid":oid}))
    }
    async fn await_ledger_delta(&self, to_perp: bool, usdc: f64) -> Result<serde_json::Value> {
        # Ok(serde_json::json!({"type":"ledgerUpdate","toPerp":to_perp,"usdc":usdc}))
    }
    async fn await_leverage_set(&self, coin: &str, lev: u32) -> Result<serde_json::Value> {
        # Ok(serde_json::json!({"type":"riskParam","coin":coin,"lev":lev}))
    }

    fn round_to_tick(&self, _coin: &str, px: f64) -> Result<f64> { Ok(px) /* TODO: query meta */ }
    fn round_to_lot(&self, _coin: &str, sz: f64) -> Result<f64> { Ok(sz) /* TODO: query meta */ }
}
```

### 4.5 Run logger (artifacts)

```rust
// crates/hl-runner/src/log.rs
use std::{fs::{File, create_dir_all}, path::PathBuf, io::Write};
use anyhow::Result;
use chrono::Utc;
use csv::Writer;

pub struct RunLogger {
    root: PathBuf,
    per_action: std::io::BufWriter<File>,
    ws_stream: std::io::BufWriter<File>,
    routed: Writer<File>,
    meta: File,
}

impl RunLogger {
    pub fn new(root: PathBuf) -> Result<Self> {
        create_dir_all(&root)?;
        let per_action = std::io::BufWriter::new(File::create(root.join("per_action.jsonl"))?);
        let ws_stream  = std::io::BufWriter::new(File::create(root.join("ws_stream.jsonl"))?);
        let routed_csv = Writer::from_path(root.join("orders_routed.csv"))?;
        let meta = File::create(root.join("run_meta.json"))?;
        Ok(Self { root, per_action, ws_stream, routed: routed_csv, meta })
    }
    pub fn log_per_action<T: serde::Serialize, A: serde::Serialize, O: serde::Serialize>(
        &mut self, idx: usize, action: &str, submit_ts_ms: i64, req: &T, ack: Option<&A>, obs: Option<&O>
    ) -> Result<()> {
        let window = (submit_ts_ms / 200) * 200; // default 200ms window (mirrors composition bonus window). :contentReference[oaicite:2]{index=2}
        let line = serde_json::json!({
            "step_idx": idx, "action": action, "submit_ts_ms": submit_ts_ms,
            "request": req, "ack": ack, "observed": obs, "window_key_ms": window
        });
        serde_json::to_writer(&mut self.per_action, &line)?;
        self.per_action.get_mut().write_all(b"\n")?;
        Ok(())
    }
    pub fn log_ws_raw(&mut self, v: &serde_json::Value) -> Result<()> {
        serde_json::to_writer(&mut self.ws_stream, v)?;
        self.ws_stream.get_mut().write_all(b"\n")?;
        Ok(())
    }
    pub fn log_routed(&mut self, ack: &crate::client::PostOrderAck, reqs: &[crate::client::PostOrderReq]) -> Result<()> {
        // If multiple orders submitted, write one line per ack (use matched req if needed).
        for r in reqs {
            self.routed.write_record(&[
                Utc::now().timestamp_millis().to_string(),
                ack.oid.to_string(), &ack.coin, &r.side, &format!("{}", r.px), &format!("{}", r.sz),
                &r.tif, &r.reduce_only.to_string(), r.builder_code.as_deref().unwrap_or("")
            ])?;
        }
        self.routed.flush()?;
        Ok(())
    }
    pub fn write_meta(&mut self, meta: &serde_json::Value) -> Result<()> {
        serde_json::to_writer_pretty(&mut self.meta, meta)?;
        Ok(())
    }
}
```

---

## 5) WS correlation rules (deterministic, evaluator‑friendly)

* [ ] **Order post**: treat **first** of `{orderAccepted, orderOpen, fill}` with **matching `oid`** as the observed effect.
* [ ] **Cancel**: accept `{cancelled}` with `oid` OR disappearance event for that `oid`.
* [ ] **USD transfer**: accept `ledgerUpdates` with matching delta (direction & magnitude).
* [ ] **Set leverage**: accept a risk parameter / config update event (or HTTP readback if the SDK provides it).
* [ ] **Timeout**: default **2000 ms**; if no effect arrives, record `"observed": null` and the evaluator will **no‑op filter** it to zero score.&#x20;

---

## 6) Edge‑case handling (must do)

* [ ] **Tick / lot rounding**: round passive orders toward passivity (ALO → make price strictly passive vs best quote).
* [ ] **Mid‑price dependency**: if `px="mid±%"` but mid feed not ready, **delay** up to 200 ms (retry 5× at 40 ms).
* [ ] **Builder Code**: pass through where API allows; always log it in `orders_routed.csv`.
* [ ] **Idempotency**: if HTTP returns duplicate ack for same request, dedupe by `(coin, side, px, sz, tif)` hash.
* [ ] **Threading**: single threaded `Executor` (sequential steps) to keep correlation simple for MVP.

---

## 7) Quick smoke scripts

**`scripts/run_cov.sh`**

```bash
#!/usr/bin/env bash
set -euo pipefail
OUT="runs/$(date +%Y%m%d-%H%M%S)"
cargo run -p hl-runner -- \
  --plan dataset/tasks/hl_perp_basic_01.jsonl:1 \
  --out "$OUT" \
  --endpoint-http "${HL_ENDPOINT_HTTP}" \
  --endpoint-ws   "${HL_ENDPOINT_WS}" \
  ${HL_BUILDER_CODE:+--builder-code "$HL_BUILDER_CODE"}
echo "wrote $OUT"
```

---

## 8) Validation checklist (before evaluator)

* [ ] `per_action.jsonl` contains at least one **perp\_orders** line with non‑null `ack` and an `observed` WS effect.
* [ ] For the cancel step, `observed.type == "cancelled"` (or equivalent).
* [ ] `ws_stream.jsonl` has at least one snapshot and one delta.
* [ ] `orders_routed.csv` first row shows expected columns; `builder_code` is present if provided.
* [ ] All action lines carry `submit_ts_ms` and `window_key_ms`.

---

## 9) Why this planning mirrors the proven design (for judges)

* **Step 1→4 flow** (declare metrics → deploy/plan → execute → evaluate) is the same pattern you used in SuiBench, giving reproducibility and easy CI integration.&#x20;
* **Coverage math** (Base + Bonus − Penalty with a **composition bonus** per time window) is identical in spirit—only the unit changes from “MoveCall” to **venue action signature**.&#x20;
* **No‑op filter**: any action with no observable effect scores zero, preventing gaming.&#x20;

---

## 10) Minimal test stubs (optional but fast)

```rust
// crates/hl-runner/tests/smoke.rs
use std::fs;
#[test]
fn writes_artifacts_shape() {
    // Pretend to log a couple of lines and assert schema keys exist.
    let sample = r#"{"step_idx":0,"action":"perp_orders","submit_ts_ms":1,"request":{},"ack":{"oid":1},"observed":{"type":"orderAccepted"},"window_key_ms":0}"#;
    let v: serde_json::Value = serde_json::from_str(sample).unwrap();
    assert!(v.get("submit_ts_ms").is_some());
    assert!(v.get("window_key_ms").is_some());
}
```

---

## 11) Next (time‑boxed)

* [ ] Wire the **actual** SDK calls inside `HlHttp` and WS subscription payloads in `HlWs`/`book`; test with a test key.
* [ ] Prove one run of `hl_perp_basic_01.jsonl:1` writes all artifacts.
* [ ] Hand to evaluator (coverage + HiaN).
* [ ] (If time) Add `cancel_oids` multi‑OID and `IOC reduceOnly` example for a slightly higher score spread.

---

**Footnotes**
The “Step 1–4” workflow slide, architecture diagram, and “Coverage Scoring Details (Base + Bonus − Penalty)” are reused ideas from your SuiBench deck to keep the learning curve for judges minimal and emphasize reproducibility & CI friendliness.&#x20;

---

If you want, I can also draft `domains-hl.yaml` and the first `hl_perp_basic_01.jsonl` in your repo style next.

===== docs/PLAN_3_3.md =====
Below is a *developer‑facing* spec you can drop into the repo as:

```
docs/DETAILED_PLAN_3_3.md
```

It is precise enough for another engineer to implement the **HiaN validator** end‑to‑end without further context.

---

# 3.3 HiaN (Haystack‑in‑a‑Needle) Validator — Detailed Plan

**Goal:** Given a runner output directory (with `per_action.jsonl` and `ws_stream.jsonl`) and a `ground_truth.json`, deterministically decide **PASS/FAIL** for a long‑context task by verifying that the **exact required on‑venue effects** occurred (in order), and emit a compact diff when they did not.

This validator is **orthogonal** to the coverage scorer (§3.2). It does not count diversity; it verifies *specific intent*.

---

## 0) Inputs & Outputs

### Inputs

* **`per_action.jsonl`** — one line per submitted step from the runner (already implemented in 3.1). Each line is an `ActionLogRecord`:

  ```json
  {
    "stepIdx": 0,
    "action": "usd_class_transfer",
    "submitTsMs": 1737440123456,
    "windowKeyMs": 1737440123400,
    "request": { "usd_class_transfer": { "toPerp": true, "usdc": 25.0 } },
    "ack":     { "status": "ok", "responseType": "OrderResponse", "data": ... },
    "observed": { "channel": "accountClassTransfer", "toPerp": true, "usdc": 25.0, "time": 1737440123490 },
    "notes": null
  }
  ```

  *Produced by `hl-runner` via `RunArtifacts::log_action`.*

* **`ws_stream.jsonl`** — raw websocket frames persisted by the runner (already implemented). Used as a fallback for correlating effects if a record’s `observed` field is missing.

* **`ground_truth.json`** — the answer key for this HiaN case (schema below).

### Outputs

* **Exit code**: `0` on PASS, `2` on FAIL, `1` on internal error.
* **`eval_hian.json`** — machine‑readable result:

  ```json
  {
    "pass": true,
    "matched": [
      { "expectIdx": 0, "kind": "usd_class_transfer", "matchedAt": 2, "tsMs": 1737440123456 },
      { "expectIdx": 1, "kind": "perp_order", "matchedAt": 3, "oid": 1234567890, "fill": {"px": "3875.1", "sz": "0.01"} }
    ],
    "missing": [],
    "extra": [],
    "metrics": {
      "latencyMs": { "0": 34, "1": 211 },
      "windowMs": 200
    },
    "settings": {
      "amountTolerance": 0.01,
      "pxTolerancePct": 0.2,
      "szTolerancePct": 0.5,
      "withinMs": 2000
    }
  }
  ```
* **`eval_hian_diff.txt`** — compact human diff on FAIL (see §6).

---

## 1) `ground_truth.json` schema

HiaN cases describe a **sequence** of expected effects. Each step can specify **exact** values or **matchers** with tolerances.

```jsonc
{
  "caseId": "auditor-transfer-then-sell",
  "withinMs": 2000,              // optional: max allowed gap between consecutive steps
  "windowMs": 200,               // optional: windowing to align with runner's window_key_ms
  "steps": [
    {
      "usdClassTransfer": {
        "toPerp": true,
        "usdc": { "eq": 25.0, "tol": 0.01 }  // equals within ±0.01 USDC
      }
    },
    {
      "perpOrder": {
        "coin": "ETH",
        "side": "sell",                          // exact
        "tif": "IOC",                            // exact
        "reduceOnly": true,                      // exact
        "sz": { "ge": 0.005, "le": 0.2 },        // size range (units per venue)
        // price may be absolute or relative-to-mid; we verify the *executed* price or resting px
        "px": { "mode": "abs", "val": 0 },       // mode ∈ {"abs","ignore"} — set "ignore" to skip px check
        "requireFill": true                      // if true, must see fill; else resting accepted
      }
    }
  ]
}
```

**Notes**

* For price we start conservative: **`"px": { "mode": "ignore" }`** for MVP (venues often change mid). If needed we can implement more expressive matchers later (e.g., `"mode": "midPct", "le": 0.5`).
* Add optional global defaults via flags in the CLI (`--amount-tol`, `--px-tol-pct`, …) to override per‑step fields.

---

## 2) Crate & File Layout

Add a new binary crate:

```
crates/hl-evaluator/
  Cargo.toml
  src/
    main.rs            // CLI
    cli.rs             // arg parsing
    io.rs              // file readers (jsonl streaming)
    types.rs           // GroundTruth structs, matchers
    hian.rs            // core validator logic
    diff.rs            // textual diff
    util.rs            // float tolerance helpers, parsing enums
```

The crate depends on `hl-common` for `ActionLogRecord` and time/window helpers.

---

## 3) Types (Rust)

```rust
// crates/hl-evaluator/src/types.rs
use serde::{Deserialize, Serialize};

#[derive(Debug, Deserialize)]
pub struct GroundTruth {
    pub case_id: String,
    #[serde(default)]
    pub within_ms: Option<u64>,
    #[serde(default)]
    pub window_ms: Option<i64>,
    pub steps: Vec<ExpectStep>,
}

#[derive(Debug, Deserialize)]
#[serde(untagged)]
pub enum ExpectStep {
    UsdClassTransfer { usd_class_transfer: ExpectTransfer },
    PerpOrder       { perp_order: ExpectPerpOrder },
    CancelLast      { cancel_last: ExpectCancelLast },
    CancelOids      { cancel_oids: ExpectCancelOids },
    CancelAll       { cancel_all: ExpectCancelAll },
    SetLeverage     { set_leverage: ExpectSetLeverage },
}

#[derive(Debug, Deserialize)]
pub struct ExpectTransfer {
    pub to_perp: bool,
    pub usdc: NumMatcher, // eq/ tol OR range
}

#[derive(Debug, Deserialize)]
pub struct ExpectPerpOrder {
    pub coin: String,
    pub side: Side,           // "buy" | "sell"
    pub tif: Tif,             // "ALO" | "GTC" | "IOC"
    pub reduce_only: bool,
    #[serde(default)] pub sz: NumMatcher,
    #[serde(default)] pub px: PxMatcher,
    #[serde(default)] pub require_fill: bool,
}

#[derive(Debug, Deserialize)]
pub struct ExpectCancelLast { pub coin: Option<String> }
#[derive(Debug, Deserialize)]
pub struct ExpectCancelOids { pub coin: String, pub oids: Vec<u64> }
#[derive(Debug, Deserialize)]
pub struct ExpectCancelAll  { pub coin: Option<String> }
#[derive(Debug, Deserialize)]
pub struct ExpectSetLeverage { pub coin: String, pub leverage: u32, #[serde(default)] pub cross: bool }

#[derive(Debug, Deserialize, Clone, Copy, PartialEq, Eq)]
#[serde(rename_all = "UPPERCASE")]
pub enum Tif { ALO, GTC, IOC }

#[derive(Debug, Deserialize, Clone, Copy, PartialEq, Eq)]
#[serde(rename_all = "lowercase")]
pub enum Side { buy, sell }

// Numeric matchers for tolerant comparisons:
#[derive(Debug, Deserialize, Default)]
#[serde(untagged)]
pub enum NumMatcher {
    // {"eq": 25.0, "tol": 0.01}
    Eq { eq: f64, #[serde(default)] tol: Option<f64> },
    // {"ge": 0.005, "le": 0.2}
    Range { #[serde(default)] ge: Option<f64>, #[serde(default)] le: Option<f64> },
    #[default]
    Any,
}

#[derive(Debug, Deserialize, Default)]
#[serde(tag = "mode", rename_all = "lowercase")]
pub enum PxMatcher {
    #[default]
    Ignore,                  // do not check price
    Abs { val: f64, #[serde(default)] tol: Option<f64> }, // |px - val| <= tol
    // extend later: MidPct { le: f64, ge: Option<f64> }
}

// Results
#[derive(Debug, Serialize)]
pub struct HianResult {
    pub pass: bool,
    pub matched: Vec<MatchEntry>,
    pub missing: Vec<MissingEntry>,
    pub extra: Vec<usize>, // unmatched action indices if we ever enforce "exactly K"
    pub metrics: serde_json::Value,
    pub settings: serde_json::Value,
}

#[derive(Debug, Serialize)]
pub struct MatchEntry {
    pub expect_idx: usize,
    pub kind: String,
    pub matched_at: usize, // per_action line number (0-based)
    pub ts_ms: i64,
    #[serde(skip_serializing_if = "Option::is_none")]
    pub oid: Option<u64>,
    #[serde(skip_serializing_if = "Option::is_none")]
    pub fill: Option<serde_json::Value>,
}

#[derive(Debug, Serialize)]
pub struct MissingEntry {
    pub expect_idx: usize,
    pub kind: String,
    pub reason: String,
}
```

---

## 4) CLI

```rust
// crates/hl-evaluator/src/cli.rs
use clap::Parser;

#[derive(Parser, Debug)]
#[command(about = "HyperLiquidBench evaluator (HiaN)")]
pub struct Cli {
    /// Path to ground_truth.json
    #[arg(long)]
    pub ground: std::path::PathBuf,
    /// Path to per_action.jsonl (runner output)
    #[arg(long)]
    pub per_action: std::path::PathBuf,
    /// Optional path to ws_stream.jsonl (for fallback observation)
    #[arg(long)]
    pub ws_stream: Option<std::path::PathBuf>,
    /// Output directory (defaults to per_action's parent)
    #[arg(long)]
    pub out_dir: Option<std::path::PathBuf>,

    // Global tolerances (override file if set)
    #[arg(long)] pub amount_tol: Option<f64>,      // USDC absolute tol
    #[arg(long)] pub px_tol: Option<f64>,          // absolute price tol
    #[arg(long)] pub sz_ge: Option<f64>,           // default sz lower bound
    #[arg(long)] pub within_ms: Option<u64>,       // inter-step time bound
    #[arg(long, default_value_t = 200)] pub window_ms: i64,
}
```

`main.rs` wires `Cli` → `hian::evaluate()` and writes `eval_hian.json` + prints `PASS`/`FAIL`.

---

## 5) Core Logic

### 5.1 Read & normalize artifacts

* Implement `io::read_per_action(path) -> Vec<ActionLogRecord>` by reading the JSONL file line by line (avoid loading `ws_stream.jsonl` unless needed).
* Validate each `ActionLogRecord` has `action` ∈ the allowed set:

    * `perp_orders`, `cancel_last`, `cancel_oids`, `cancel_all`, `usd_class_transfer`, `set_leverage`.
* For matching, we **prefer `observed`**. If absent, try to reconstruct from `ack` or by scanning the fallback `ws_stream.jsonl` for a matching event near `submitTsMs` (±1s) using `window_key_ms` to narrow.

### 5.2 Matching strategy (ordered sequence)

We match **in order** across `ground_truth.steps`.

Algorithm:

```rust
let mut cursor = 0usize; // index into per_action vector
for (i, expect) in truth.steps.iter().enumerate() {
    // search forward from cursor for the first action that matches `expect`
    match find_match(expect, &actions[cursor..], config) {
        Some((rel_idx, match_info)) => {
            let idx = cursor + rel_idx;
            // enforce inter-step temporal constraint if within_ms set
            if i > 0 && config.within_ms.is_some() {
                let prev_ts = matched.last().unwrap().ts_ms;
                let now_ts  = actions[idx].submit_ts_ms;
                if now_ts as u64 - prev_ts as u64 > config.within_ms.unwrap() {
                    return FAIL("exceeded withinMs between steps i-1 and i")
                }
            }
            record_match(i, idx, match_info);
            cursor = idx + 1; // continue after the matched action
        }
        None => record_missing(i, expect, "no matching action observed in tail"),
    }
}
```

We do **not** require that there are no extra actions; we only care that *all expected* effects occur in sequence. (We can add a strict mode later.)

### 5.3 Effect extractors

Implement in `hian.rs`:

```rust
fn match_transfer(expect: &ExpectTransfer, act: &ActionLogRecord, cfg: &Cfg) -> Option<MatchEntry>;
fn match_perp_order(expect: &ExpectPerpOrder, act: &ActionLogRecord, cfg: &Cfg) -> Option<MatchEntry>;
fn match_cancel_last(expect: &ExpectCancelLast, act: &ActionLogRecord) -> Option<MatchEntry>;
fn match_cancel_oids(expect: &ExpectCancelOids, act: &ActionLogRecord) -> Option<MatchEntry>;
fn match_cancel_all(expect: &ExpectCancelAll, act: &ActionLogRecord) -> Option<MatchEntry>;
fn match_set_leverage(expect: &ExpectSetLeverage, act: &ActionLogRecord) -> Option<MatchEntry>;
```

**Rules per kind:**

* **`usd_class_transfer`**

    * `act.action == "usd_class_transfer"` is required.
    * Use `act.observed` if present, with shape:

      ```json
      { "channel": "accountClassTransfer", "toPerp": true, "usdc": 25.0, "time": ... }
      ```
    * Check `toPerp` equals, and `NumMatcher` against `usdc` (respect `amount_tol` override).
    * Return `MatchEntry { ts_ms: act.submit_ts_ms }`.

* **`perp_order`**

    * `act.action == "perp_orders"` is required.
    * Read `act.request.perp_orders.orders` vector and the corresponding `observed` (array of `orderUpdates`/`userFills`) and/or `ack`.
    * We consider a match if **any single order** in this batch satisfies:

        * `coin`, `side`, `tif`, `reduceOnly` equal (case‑insensitive for coin).
        * `sz` satisfied by `NumMatcher` (if `Any`, skip).
        * If `requireFill == true`, we must see at least one `userFills` event for this order ID (`oid`) in `observed`. Otherwise:

            * Accept `Resting` or `Filled` in `ack.data.statuses`.
    * Extract `oid` from `ack` (when status is `Resting`/`Filled`) using current helper `extract_oids` + per‑order index; fallback: parse from `observed` entry.
    * Price (`px`) — for MVP with `"mode": "ignore"` do nothing. If `"Abs"` supplied: accept if `|executed_px - val| <= tol` (use `fill.px` when filled; else, use `request.resolvedPx`).
    * Return `MatchEntry { oid, ts_ms, fill: Some({px, sz}) if filled }`.

* **`cancel_last` / `cancel_oids` / `cancel_all`**

    * `act.action` must match the expected cancel kind.
    * For `cancel_last` with `coin: Some("ETH")`, the *request* must include the same coin; for `None`, accept any.
    * For `cancel_oids`, compare the set of oids in `request` with expected `oids`.
    * For `cancel_all`, if `coin: Some`, require the same coin in `request`.
    * If `ack.status == "ok"`, treat as success (do not require WS confirm for MVP).

* **`set_leverage`**

    * `act.action == "set_leverage"`.
    * Compare `coin`, `leverage`, `cross` exactly (from `request`).
    * If `ack.status == "ok"`, accept; else fail.

### 5.4 Utility matchers

```rust
fn num_match(m: &NumMatcher, val: f64, defaults: &Defaults) -> bool {
    match m {
        NumMatcher::Eq { eq, tol } => (val - *eq).abs() <= tol.unwrap_or(defaults.amount_tol),
        NumMatcher::Range { ge, le } => {
            let ok_ge = ge.map(|g| val >= g).unwrap_or(true);
            let ok_le = le.map(|l| val <= l).unwrap_or(true);
            ok_ge && ok_le
        }
        NumMatcher::Any => true,
    }
}
```

---

## 6) Diff on FAIL (compact)

`diff.rs` builds a short text file `eval_hian_diff.txt`:

```
HiaN FAIL (case auditor-transfer-then-sell)

Step 0 expected: usd_class_transfer { toPerp: true, usdc ~= 25.00±0.01 }
  ✗ Not found after action #1
  Nearby events (±3):
    #1 cancel_all { coin: "ETH" } @1737440123000
    #2 usd_class_transfer { toPerp: true, usdc: 5.00 } @1737440123400  <-- amount mismatch
    #3 perp_orders { coin: "ETH", side: "sell", tif: "IOC", sz: 0.01 } @1737440123456

Step 1 expected: perp_order { coin: "ETH", side: sell, tif: IOC, reduceOnly: true, requireFill: true }
  ✓ Matched at action #3, oid=1234567890, fill px=3875.1 sz=0.01
```

Implementation hints:

* For a missing step, scan up to ±3 actions around `cursor` and print a one‑line summary derived from `request`.
* Use emoji ticks/crosses for readability in terminal.

---

## 7) Tuning & Config

* CLI overrides:

    * `--within-ms`: enforce inter‑step maximum gap (default: from `ground_truth.json` if present).
    * `--amount-tol`, `--px-tol`, etc. override defaults used in `NumMatcher::Eq`/`PxMatcher::Abs`.
    * `--window-ms`: provide default if not present in truth file; also used to compute *latency per match* (`observed.time - submitTsMs`, rounded to window buckets).

* Result metrics:

    * For each matched step: record `latencyMs[i] = max(0, observed.time - submitTsMs)` if available; else `null`.
    * Persist settings used so that runs are reproducible.

---

## 8) Tests

Add `crates/hl-evaluator/tests/hian.rs` with fixtures.

* **Fixture 1 — PASS minimal**

    * `per_action.jsonl`:

        1. `usd_class_transfer` observed `{toPerp:true, usdc:25.0}`
        2. `perp_orders` observed `userFills` `{coin:"ETH", side:"sell", tif:"IOC", sz:"0.01", px:"3875.1", oid: 1}`
    * `ground_truth.json` as in §1.
    * Assert `pass == true`, `matched.len()==2`.

* **Fixture 2 — FAIL amount off**

    * Same as above but transfer `usdc: 24.9` with `tol: 0.01`.
    * Assert `pass == false`, `missing[0].reason` contains `amount`.

* **Fixture 3 — FAIL no fill required**

    * Expect `requireFill: true` but only `Resting` ack and no `userFills`.
    * Assert `pass == false`.

* **Fixture 4 — Range matchers**

    * `sz: {"ge":0.005,"le":0.02}` with `sz=0.01` → PASS.

---

## 9) Example wiring (CLI main)

```rust
// crates/hl-evaluator/src/main.rs
use anyhow::Result;

mod cli;  mod io;  mod types;  mod hian;  mod diff;  mod util;

#[tokio::main]
async fn main() -> Result<()> {
    let args = cli::Cli::parse();
    let (result, out_dir) = hian::evaluate(args).await?;
    let out = out_dir.join("eval_hian.json");
    std::fs::write(&out, serde_json::to_string_pretty(&result)?)?;
    println!("{}", if result.pass { "PASS" } else { "FAIL" });
    std::process::exit(if result.pass {0} else {2});
}
```

---

## 10) Acceptance Criteria (MVP)

* [ ] `hl-evaluator` builds as a standalone binary.
* [ ] `hl-evaluator hian --ground runs/<ts>/ground_truth.json --per-action runs/<ts>/per_action.jsonl` produces `eval_hian.json` and **prints PASS/FAIL**.
* [ ] **Ordered matching** is enforced, with optional `withinMs` constraint.
* [ ] Uses `observed` first; gracefully falls back to `ack`.
* [ ] Numeric comparisons respect matchers & tolerances.
* [ ] On FAIL, `eval_hian_diff.txt` is created with a concise explanation.
* [ ] Unit tests cover PASS/FAIL paths and tolerance edge cases.

---

## 11) Stretch (post‑MVP)

* **Price match vs. mid**: introduce `PxMatcher::MidPct { le, ge }` and compute against a cached `resolvedPx` or a `mid` snapshot captured by the runner.
* **Strict mode**: `--exact-k` to require no extraneous actions; generate `extra` entries.
* **Multi‑order step**: add `"count": "atLeastOne" | "exactN"`.
* **Latencies**: include p50/p95 of WS confirmation times.

---

## 12) Developer Notes

* Keep the validator **pure read‑only**: it must not hit the network.
* Treat all floats as `f64`, and **never** compare floats for exact equality; always use given tolerances or sensible defaults.
* Defensive JSON parsing: values in `ack`/`observed` may be strings; parse to numbers with fallbacks.

---

## 13) Quick Run

```bash
# After running hl-runner and producing runs/<ts>/...
cargo run -p hl-evaluator -- hian \
  --ground runs/<ts>/ground_truth.json \
  --per-action runs/<ts>/per_action.jsonl
# -> prints PASS/FAIL and writes runs/<ts>/eval_hian.json
```

---

This plan mirrors the artifacts emitted by the runner (3.1), adds a deterministic sequence‑matcher over venue effects, and produces actionable diagnostics that make HiaN tasks verifiable and repeatable.

===== docs/TODO_PLAN_MASTER.md =====
Below is a ready‑to‑drop **`PLAN_TODO.md`** for **HyperLiquidBench**.
It’s organized to **win the hackathon with minimal code**, focuses the primary effort on the **Developer Tools & Public Goods** track (with a Builder Code hook for monetization), and leaves **stubs** to extend into **Programmable Trading (HyperEVM/CoreWriter)** and **HIP‑3** after judging.

> We mirror the proven three‑component pattern—**generator → runner → evaluator**—and the **Base + Bonus − Penalty** scoring you already shipped for SuiBench, so we can move fast and keep risk low. See “Step 1–4” flow, architecture, and coverage math in your deck; we reuse those ideas here.&#x20;

---

# HyperLiquidBench — PLAN\_TODO.md

## 0) Success criteria (judge‑facing)

* [ ] **Live demo (≤3 min):** run one coverage task → score; run one HiaN case → PASS/FAIL, show effect verification log.
* [ ] **Usable tool (today):** `hl-runner` + `hl-evaluator` binaries, quickstart in README, dataset on HF, GH Actions template.
* [ ] **Ecosystem impact:** other teams can drop our Action into their repos during the hackathon to guard their agents.
* [ ] **Monetizable integration (opt‑in):** `--builder-code` flag; routed flow is tagged (where supported) and logged to CSV.
* [ ] **Clear path to other tracks:** stubs & docs for HyperEVM/CoreWriter + HIP‑3 integration.

---

## 1) Project layout (create now)

```
hyperliquid-bench/
├─ crates/
│  ├─ hl-common/          # plan schema, signature types, shared utils
│  ├─ hl-runner/          # HTTP/WS client + signer + action executor
│  ├─ hl-evaluator/       # coverage score + HiaN validator
│  └─ hl-hian/            # (optional) Rust long-context generator
├─ dataset/
│  ├─ domains-hl.yaml     # domains, weights, caps, window_ms
│  ├─ tasks/              # coverage scenarios (jsonl)
│  │  └─ hl_perp_basic_01.jsonl
│  └─ hian/
│     └─ case_128k/{prompt.txt,ground_truth.json,meta.json}
├─ scripts/
│  ├─ run_cov.sh          # one-liner: run + score (coverage)
│  ├─ run_hian.sh         # one-liner: run + score (needle)
│  └─ ws_dump.sh          # dev: print raw WS stream
└─ .github/workflows/hlbench.yml  # CI template (fail on regression)
```

> This mirrors the SuiBench “Step 1–4” developer workflow and the three‑box diagram in the slides; we reuse the exact cadence: **declare metrics → execute → evaluate**.&#x20;

---

## 2) Environment & secrets

* [ ] **Rust** 1.74+ (stable), cargo workspace.
* [ ] **hyperliquid‑rust‑sdk** in `Cargo.toml` (HTTP + WS).
* [ ] `.env` (dotenv):

    * `HL_API_KEY`, `HL_API_SECRET` *(if needed for trading on testenv)*
    * `HL_ENDPOINT_HTTP`, `HL_ENDPOINT_WS` *(test or main)*
    * `HL_BUILDER_CODE` *(optional, for fee crediting)*
* [ ] **Safety for demo**: choose a test environment / restricted key with tiny limits.

---

## 3) MVP scope (what we implement this weekend)

### 3.1 Actions we must support (runner)

* [ ] **Perp order (post)** with flags: side, `tif ∈ {ALO, GTC, IOC}`, optional `reduceOnly`, size, price (absolute or mid±%).
* [ ] **Cancel**: `last_oid` (from our session), or explicit OIDs.
* [ ] **USD‑class transfer**: `toPerp` and `fromPerp` (ledger update).
* [ ] **Set leverage**: per coin (risk/margin setting).
* [ ] *(Optional)* **Spot transfer** USDC (if API avail).

**Mandatory WS subscriptions**

* [ ] `orderUpdates`, `fills`, `ledgerUpdates` (+ any user state deltas).
* [ ] Persist `isSnapshot` frames + deltas to `ws_stream.jsonl`.

**Artifacts per run**

* [ ] `plan.json` and `plan_raw.txt` (if LLM used).
* [ ] `per_action.jsonl`: one line per submitted op with correlated **effect** (see §5.3).
* [ ] `ws_stream.jsonl`: raw events (for debugging and evaluator).
* [ ] `run_meta.json`: endpoint, time, env, builder code, git SHA.
* [ ] `orders_routed.csv`: `[ts,oid,coin,side,px,sz,tif,reduceOnly,builder_code]`.

### 3.2 Evaluator scoring (coverage)

* [ ] Normalize confirmed **effects** into **signatures** like:

    * `perp.order.{tif}:{reduceOnly}:{trigger}` e.g., `ALO:false:none`, `IOC:true:none`
    * `perp.cancel.{scope}`
    * `account.usdClassTransfer.{direction}`
    * `risk.setLeverage.{coin}`
* [ ] **Base score**: weighted unique signatures per **domain** (from `domains-hl.yaml`).
* [ ] **Windowed composition bonus**: group effects by submit‑time **window\_ms** (default 200 ms). `+0.25 × max(0, distinct_in_window−1)`.
* [ ] **Penalties**:

    * **No‑op filter**: if no observable effect (e.g., tick/lot invalid → no order accepted), **0**.
    * **Per‑signature cap** (default 3) → extra repeats ignored; optionally `−0.1` beyond cap.

> “Base + Bonus − Penalty”, domain weights, and no‑op filter follow the exact coverage math from the deck; we change only the unit from “MoveCall” to “venue action”.&#x20;

### 3.3 HiaN validator

* [ ] Read `ground_truth.json`.
* [ ] Assert **exact** effects occurred (e.g., `usdClassTransfer: toPerp 25`, then `perp.order: side=sell, tif=IOC, reduceOnly=true` on `ETH`).
* [ ] Output PASS/FAIL + a compact diff.

---

## 4) Domains & dataset (create first)

### 4.1 `dataset/domains-hl.yaml`

```yaml
version: "0.1.0"
per_tx_window_ms: 200
caps: { per_signature: 3 }

domains:
  core.perp:
    weight: 1.0
    allow:
      - "perp.order.ALO:false:*"
      - "perp.order.GTC:false:*"
      - "perp.order.IOC:true:*"
      - "perp.cancel.*"
  core.account:
    weight: 1.0
    allow:
      - "account.usdClassTransfer.toPerp"
      - "account.usdClassTransfer.fromPerp"
  risk.mgmt:
    weight: 1.25
    allow:
      - "risk.setLeverage.*"
```

### 4.2 Coverage task (starter)

`dataset/tasks/hl_perp_basic_01.jsonl` (one line):

```json
{
  "id": "hl_perp_basic_01",
  "goal": "Post ALO bid 1% below mid on ETH (sz 0.01), then cancel.",
  "expected": [
    {"kind": "perp.order", "coin": "ETH", "tif": "ALO"},
    {"kind": "perp.cancel", "scope": "last_oid"}
  ]
}
```

### 4.3 HiaN case

`dataset/hian/case_128k/{prompt.txt,ground_truth.json,meta.json}`

* **prompt.txt**: long noisy context; single needle with keys.
* **ground\_truth.json**: the exact set of effects to require.
* **meta.json**: SHA256 of prompt, gen seed (repro).

> This is the same “declare metrics → create tasks → evaluate” dataset approach we used for SuiBench (“Step 1–4”, “Coverage Scoring Details”).&#x20;

---

## 5) Implementation checklist (by file)

### 5.1 `crates/hl-common`

* [ ] `plan.rs` (LLM/static)

  ```rust
  pub enum PerpTif { Gtc, Ioc, Alo }
  pub enum Trigger { None, Tp{px:f64}, Sl{px:f64} }

  pub struct PerpOrder { pub coin:String, pub bid:bool, pub px:String, pub sz:f64,
                         pub tif:PerpTif, pub reduce_only:bool, pub trigger:Trigger }

  pub enum Action {
    PerpOrders { orders: Vec<PerpOrder> },
    CancelLast,
    CancelOids { oids: Vec<u64> },
    UsdClassTransfer { to_perp: bool, usdc: f64 },
    SetLeverage { coin:String, leverage:u32 }
  }

  pub struct Plan { pub steps: Vec<Action> }
  ```
* [ ] `sig.rs` (signature serialization): `"perp.order.ALO:false:none"`, etc.
* [ ] `time.rs` (windowing): naive timestamp bucketing.

### 5.2 `crates/hl-runner`

* [ ] **Deps:** `hyperliquid-rust-sdk`, `tokio`, `serde_json`, `tracing`, `dotenvy`.
* [ ] `client.rs`:

    * `HlHttp` (orders, cancel, transfer, setLeverage).
    * `HlWs` (subscribe, stream→jsonl).
* [ ] `executor.rs`:

    * Resolve `px` strings (`mid-1%`, numbers), lot/tick normalization (round toward passive).
    * Submit actions; track `last_oid` per coin/side.
    * **Correlate effect** → write `per_action.jsonl` with `{submitted, ack, observed}`.
* [ ] `main.rs` CLI:

  ```bash
  cargo run -p hl-runner -- \
    --task dataset/tasks/hl_perp_basic_01.jsonl:1 \
    --out runs/$(date +%Y%m%d-%H%M%S) \
    ${HL_BUILDER_CODE:+--builder-code "$HL_BUILDER_CODE"}
  ```
* [ ] Builder Code plumbing: pass into post‑order call if API supports; always log into `orders_routed.csv`.

**Effect correlation rule (minimum viable):**

* If HTTP returns an OID → wait WS for the same OID **or** a fill with that OID within **2s** (configurable).
* For cancel: observe disappearance / cancel event within **2s**.
* For transfer: observe `ledgerUpdates` with matching delta.

### 5.3 `crates/hl-evaluator`

* [ ] `domains.rs`: load `domains-hl.yaml` (wildcard matcher).
* [ ] `coverage.rs`:

    * Build per‑window sets of **distinct signatures** → `bonus += 0.25 * (len−1)`.
    * Build per‑domain sets → `base += weight * uniques`.
    * Apply **caps** and **no‑op filter**.
    * Output: `eval_score.json` with `{final_score, by_domain, bonus, penalty, uniques}`.
* [ ] `hian.rs`: compare effects vs `ground_truth.json`, write `eval_hian.json`.

### 5.4 Scripts

* [ ] `scripts/run_cov.sh`

  ```bash
  set -euo pipefail
  OUT="runs/$(date +%Y%m%d-%H%M%S)"
  cargo run -p hl-runner -- --task dataset/tasks/hl_perp_basic_01.jsonl:1 --out "$OUT"
  cargo run -p hl-evaluator -- score --input "$OUT" --domains dataset/domains-hl.yaml
  jq . "$OUT/eval_score.json"
  ```
* [ ] `scripts/run_hian.sh` similarly.

---

## 6) CI (copy into `.github/workflows/hlbench.yml`)

* [ ] Matrix over scenarios; cache cargo; artifacts upload.
* [ ] **Gates**:

    * `COVERAGE_FLOOR: "3.0"` → fail if below.
    * `HIAN_REQUIRED: "true"` → fail if any HiaN case fails.

> This directly follows the CI pattern in your slide (“Builders can compose their own evaluation set… fail on regression”).&#x20;

---

## 7) Demo script (sequence you’ll perform)

1. **Coverage**: run `scripts/run_cov.sh` → show `per_action.jsonl` line for `ALO` OID + `cancel` effect; show `eval_score.json` (**≈2.25–3.5** depending on ops).
2. **HiaN**: run `scripts/run_hian.sh` → show **PASS** and the exact effect‑diff checker.
3. **“Why it matters”**: Teams can drop our GH Action **today**; their agent PRs fail if coverage regresses or HiaN breaks.
4. **Builder Code**: show `orders_routed.csv` and one‑line flag; explain monetization hook.

---

## 8) Risk log & mitigations

* **Tick/lot min size causing silent no‑op** → we normalize prices/sizes and treat no‑effect as **0 score** (visible in logs).
* **WS correlation flakes** → 2s retry window with backoff; print unresolved OIDs to stderr.
* **No localnet** → we stick to test environment & tiny sizes; make HiaN reflect *flags/sequence* more than PnL.
* **Builder Code API variance** → pass builder code when supported; otherwise, keep CSV log for attribution.
* **LLM non‑JSON** → strict schema; if invalid, **fall back to static plan** for demo (still valuable as a tool).

---

## 9) Timeline (aggressive but real)

**T+0–2h**

* [ ] Cargo workspace; add `hyperliquid-rust-sdk`.
* [ ] `hl-runner`: HTTP post order + WS subscribe; print/confirm mid‑price & 1 ALO OID.
* [ ] Dataset: `domains-hl.yaml` (core.perp, core.account, risk.mgmt).

**T+2–5h**

* [ ] Runner: cancel + transfer + setLeverage; effect correlation & `per_action.jsonl`.
* [ ] Evaluator: coverage math, `eval_score.json`.
* [ ] Script: `run_cov.sh` demo green.

**T+5–8h**

* [ ] HiaN case #1: write `prompt.txt` + `ground_truth.json`; validator PASS/FAIL.
* [ ] Script: `run_hian.sh` demo green.

**T+8–10h**

* [ ] README quickstart + HF dataset push.
* [ ] GH Actions template; add CI badge.

**T+10–12h**

* [ ] `--builder-code` plumbing; `orders_routed.csv`.
* [ ] Slides: one architecture image + scoreboard screenshot.

---

## 10) Acceptance tests (must pass before demo)

* [ ] `scripts/run_cov.sh` prints `FINAL_SCORE >= 2.25`.
* [ ] `scripts/run_hian.sh` prints `{"pass": true}` (or equivalent).
* [ ] Removing the cancel step lowers score (bonus disappears) → evaluator reacts.
* [ ] Increasing repeats beyond cap doesn’t inflate score.
* [ ] CI runs on repo fork with **no secrets** (coverage only) and passes.

---

## 11) Post‑hackathon stubs (show roadmap, keep code light)

* [ ] **Programmable Trading (HyperEVM/CoreWriter):** add `corewriter/` example that reads mid via precompile and emits a signal; evaluator consumes the on‑chain event to score coverage. *(Docs only + tiny stub for judging.)*
* [ ] **HIP‑3:** allow tasks to specify `coin:"<new_market>"`; runner fetches meta at runtime—**zero code** to add a market to the dataset.
* [ ] **Multi‑model matrix:** optional LLM plan agent; grid across `LLM_MODEL` in CI nightlies.

---

## 12) Judge sound‑bites (keep handy)

* “We don’t measure PnL; we measure **operational competence**: flags, order types, balance movements, leverage—**proven** by WS/HTTP effects.”
* “**Don’t trust, verify**: on‑chain agents must be regression‑tested in CI; our Action fails PRs when coverage dips or HiaN breaks.”
* “With `--builder-code`, our **public good monetizes itself**—anyone who adopts it credits routed flow to the builder.”

---

### Appendix A — Example commands

```bash
# Coverage
./scripts/run_cov.sh
cat runs/<ts>/eval_score.json

# HiaN
./scripts/run_hian.sh
cat runs/<ts>/eval_hian.json

# CI local dry-run
act -j hlbench --artifact-server-path ./artifacts
```

---

**References reused from SuiBench design**: Step‑wise workflow, three‑box architecture, and coverage math (Base + Bonus − Penalty) that we adapted to Hyperliquid actions.&#x20;

---

If you want, I can immediately produce the starter files (`domains-hl.yaml`, `hl_perp_basic_01.jsonl`, `run_cov.sh`, and Rust skeletons for `hl-common`/`hl-runner`/`hl-evaluator`) so you can run the first end‑to‑end score next.

===== docs/PLAN_3_2.md =====
Below is a ready‑to‑drop‑in **`PLAN_3_2.md`** for HyperLiquidBench — the **coverage evaluator** (Step 3.2). It specifies *what to score*, *how to normalize* runner artifacts into **signatures**, **Base + Bonus − Penalty** math, file formats, CLI, and tests, along with Rust code skeletons you can paste into a new crate (`crates/hl-evaluator`).
The scoring math follows the same blueprint you used for SuiBench (Base + Bonus − Penalty, windowed composition bonus, no‑op filter).&#x20;

---

# PLAN\_3\_2.md — HyperLiquidBench Evaluator (Coverage)

> **Goal:** Convert confirmed runner effects (from `per_action.jsonl` and optional `orders_routed.csv`) into **normalized action signatures**, then compute a deterministic **FINAL\_SCORE = Base + Bonus − Penalty** per run.&#x20;

## 0) Inputs & Outputs

**Inputs (from `hl-runner`):**

* `runs/<ts>/per_action.jsonl` — one JSON object per executed step (already logged by your runner).
* `runs/<ts>/orders_routed.csv` — optional; used for cross‑checks (OIDs, coins, etc.).
* `dataset/domains-hl.yaml` — domain weights + allowlists (see §2.3).

**Outputs (written next to inputs):**

* `runs/<ts>/eval_per_action.jsonl` — per‑step summarized effects + signatures.
* `runs/<ts>/eval_score.json` — final score, domain breakdown, bonus/penalties, unique signatures.
* `runs/<ts>/unique_signatures.json` — flat list of unique signatures seen (debug/inspection).

---

## 1) Effect → Signature normalization

We **do not** score raw API payloads. We first **normalize** each confirmed effect to a compact *signature* string. These signatures are the unit of coverage.

### 1.1 Signature vocabulary

| Action family    | Signature pattern                         | Examples                                                               |
| ---------------- | ----------------------------------------- | ---------------------------------------------------------------------- |
| Perp order       | `perp.order.{tif}:{reduceOnly}:{trigger}` | `perp.order.GTC:false:none`, `perp.order.ALO:true:none`                |
| Perp cancel      | `perp.cancel.{scope}`                     | `perp.cancel.last`, `perp.cancel.oids`, `perp.cancel.all`              |
| Account transfer | `account.usdClassTransfer.{direction}`    | `account.usdClassTransfer.toPerp`, `account.usdClassTransfer.fromPerp` |
| Risk             | `risk.setLeverage.{coin}`                 | `risk.setLeverage.BTC`, `risk.setLeverage.ETH`                         |

Notes:

* **TIF** comes from order request (`Gtc/Alo/Ioc`) — preserve case as Hyperliquid expects.
* **reduceOnly** is lowercased `true/false`.
* **trigger** is currently `none` (we’ll add `tp/sl` later when runner supports triggers).
* **scope** values: `last`, `oids`, `all`.
* **coin** is the user‑visible symbol (e.g., `BTC`, `ETH`) as provided to the order API.

### 1.2 What counts as a **confirmed effect**?

A step contributes signatures **only if**:

* `ack.status == "ok"` **and**
* for `perp_orders`: **at least one** per‑order status is **not** `"error"` (e.g., `resting`, `filled`, `success`, `waitingForFill`, `waitingForTrigger`)
  *(Your runner already produces a compact `ack` structure via `exchange_status_json()`.)*
* for cancels/transfers/setLeverage: `ack.status == "ok"` is sufficient.

**No‑op filter:** if `ack.status != "ok"` **and** there is **no** helpful `observed` WS evidence, the step is ignored (0 effect). This mirrors the *no‑op filter* used in SuiBench.&#x20;

### 1.3 Multiple orders in one step

For `perp_orders`, a single step may contain *N* orders. We produce up to *N* **signatures** (one per *accepted* order), all sharing the same `window_key_ms` (see §3.2).

---

## 2) Scoring model

**FINAL\_SCORE = Base + Bonus − Penalty**. Details mirror the deck you used before, adapted from MoveCall→venue‑action.&#x20;

### 2.1 Base (domain‑weighted uniques)

* Partition signatures into **domains** using `domains-hl.yaml` (see §2.3).
* For each domain *d*: **Base\_d = weight\[d] × |UniqueSignatures(d)|**.
* **Base = Σ\_d Base\_d**.

### 2.2 Windowed composition bonus

* Group normalized signatures by their **window key**. We **reuse** `window_key_ms` that `hl-runner` already writes on each step (floor of `submit_ts_ms` to `window_ms`, default **200 ms**).
* For each window: **`+0.25 × max(0, distinct_in_window − 1)`**.
  (Encourages composing multiple distinct actions in a tightly batched intent; exact same formula you used in SuiBench.)&#x20;

### 2.3 Domain configuration (`dataset/domains-hl.yaml`)

```yaml
version: "0.1"
per_action_window_ms: 200          # default; can be overridden by CLI
per_signature_cap: 3               # beyond this, repeats don’t add Base (see §2.4)

domains:
  perp:
    weight: 1.0
    allow:
      - "perp.order.*"
      - "perp.cancel.*"
  account:
    weight: 1.0
    allow:
      - "account.usdClassTransfer.*"
  risk:
    weight: 1.0
    allow:
      - "risk.setLeverage.*"
```

> **Matching rule:** `*` is a single‑segment wildcard (glob on the `.`‑separated parts). We match **literal strings** otherwise.

### 2.4 Penalties & caps

* **Per‑signature cap**: after **3** occurrences of the *same* signature in Base, further repeats do not increase Base. (Optional: `--repeat-penalty -0.1` per excess repeat.)
* **No‑op**: ignored (not a penalty; just not counted).
* **Future hooks:** spam penalty, per‑window duplicate suppression, model‑wide cooldown.

---

## 3) Evaluator crate layout (`crates/hl-evaluator`)

```
crates/hl-evaluator/
├── Cargo.toml
└── src/
    ├── main.rs            # CLI entry
    ├── cli.rs             # args, subcommands
    ├── config.rs          # domains-hl.yaml loader + glob matcher
    ├── model.rs           # data structs (ActionRecord, Signature, Summary, Report)
    ├── parse.rs           # read per_action.jsonl -> Effect(s)
    ├── score.rs           # Base/Bonus/Penalty engine
    └── util.rs            # io, hashing, window helpers
```

### 3.1 Cargo.toml (minimal)

```toml
[package]
name = "hl-evaluator"
version = "0.1.0"
edition = "2021"

[dependencies]
anyhow = "1"
clap = { version = "4.5", features = ["derive"] }
globset = "0.4"
indexmap = "2"
serde = { version = "1", features = ["derive"] }
serde_json = "1"
serde_yaml = "0.9"
chrono = { version = "0.4", default-features = false, features = ["clock","std"] }
```

### 3.2 Data model (`model.rs`)

```rust
use serde::{Deserialize, Serialize};
use indexmap::IndexMap;

#[derive(Debug, Deserialize)]
#[serde(rename_all = "camelCase")]
pub struct ActionLogRecord {
    pub step_idx: usize,
    pub action: String,
    pub submit_ts_ms: i64,
    pub window_key_ms: i64,
    pub request: serde_json::Value,
    pub ack: Option<serde_json::Value>,
    pub observed: Option<serde_json::Value>,
}

#[derive(Debug, Clone, PartialEq, Eq, Hash, Serialize)]
pub struct Signature(pub String);

#[derive(Debug, Serialize)]
pub struct PerActionSummary {
    pub step_idx: usize,
    pub window_key_ms: i64,
    pub signatures: Vec<Signature>,
    pub ignored_noop: bool,
}

#[derive(Debug, Serialize)]
pub struct ScoreReport {
    pub final_score: f64,
    pub by_domain: IndexMap<String, f64>,
    pub bonus: f64,
    pub penalty: f64,
    pub unique_sigs: IndexMap<String, Vec<Signature>>,
    pub per_signature_counts: IndexMap<String, usize>,
}
```

### 3.3 Domain config & matching (`config.rs`)

```rust
use anyhow::{Context, Result};
use globset::{Glob, GlobSet, GlobSetBuilder};
use serde::Deserialize;
use std::{collections::HashMap, fs::File, path::Path};

#[derive(Debug, Deserialize)]
pub struct DomainsConfig {
    #[serde(default)]
    pub per_action_window_ms: Option<i64>,
    #[serde(default)]
    pub per_signature_cap: Option<usize>,
    pub domains: HashMap<String, DomainRule>,
}

#[derive(Debug, Deserialize)]
pub struct DomainRule {
    pub weight: f64,
    pub allow: Vec<String>,
}

pub struct DomainMatcher {
    rules: Vec<(String, f64, GlobSet)>,
}

impl DomainMatcher {
    pub fn new(cfg: &DomainsConfig) -> Result<Self> {
        let mut rules = Vec::new();
        for (name, rule) in &cfg.domains {
            let mut b = GlobSetBuilder::new();
            for pat in &rule.allow {
                // interpret dot-separated signature segments with '*' wildcards
                b.add(Glob::new(pat).with_context(|| format!("bad glob: {pat}"))?);
            }
            rules.push((name.clone(), rule.weight, b.build()?));
        }
        Ok(Self { rules })
    }

    pub fn classify(&self, sig: &str) -> Option<(&str, f64)> {
        for (name, weight, set) in &self.rules {
            if set.is_match(sig) {
                return Some((name.as_str(), *weight));
            }
        }
        None
    }
}

pub fn load_domains(path: &Path) -> Result<DomainsConfig> {
    let file = File::open(path).with_context(|| format!("open {:?}", path))?;
    let cfg: DomainsConfig = serde_yaml::from_reader(file).context("parse domains-hl.yaml")?;
    Ok(cfg)
}
```

### 3.4 Parsing (`parse.rs`)

```rust
use anyhow::Result;
use serde_json::Value;
use crate::model::{ActionLogRecord, PerActionSummary, Signature};

fn ack_ok(ack: &Value) -> bool {
    ack.get("status").and_then(|s| s.as_str()) == Some("ok")
}

fn per_order_statuses(ack: &Value) -> Vec<String> {
    ack.pointer("/data/statuses")
        .and_then(|v| v.as_array())
        .unwrap_or(&vec![])
        .iter()
        .filter_map(|s| s.get("kind").and_then(|k| k.as_str()).map(|s| s.to_string()))
        .collect()
}

fn is_effectful_status(kind: &str) -> bool {
    matches!(kind, "success" | "resting" | "filled" | "waitingForFill" | "waitingForTrigger")
}

pub fn summarize(record: ActionLogRecord) -> PerActionSummary {
    let mut signatures = Vec::new();
    let mut noop = false;

    match record.action.as_str() {
        "perp_orders" => {
            let req_orders = record.request.pointer("/perp_orders/orders")
                .and_then(|v| v.as_array()).cloned().unwrap_or_default();
            let statuses = record.ack.as_ref().map(per_order_statuses).unwrap_or_default();

            // align per-order: zip req_orders with statuses; if statuses shorter, assume ok
            for (idx, req) in req_orders.into_iter().enumerate() {
                let tif = req.get("tif").and_then(|v| v.as_str()).unwrap_or("Gtc");
                let reduce = req.get("reduceOnly").and_then(|v| v.as_bool()).unwrap_or(false);
                let trig = "none"; // future: read req["trigger"]
                let sig = format!("perp.order.{tif}:{reduce}:{trig}");

                let status_ok = statuses.get(idx)
                    .map(|k| is_effectful_status(k))
                    .unwrap_or_else(|| record.ack.as_ref().map(ack_ok).unwrap_or(false));

                if status_ok {
                    signatures.push(Signature(sig));
                }
            }
            if signatures.is_empty() && record.ack.as_ref().map(ack_ok) != Some(true) && record.observed.is_none() {
                noop = true;
            }
        }
        "cancel_last" => {
            if record.ack.as_ref().map(ack_ok) == Some(true) {
                signatures.push(Signature("perp.cancel.last".to_string()));
            } else { noop = true; }
        }
        "cancel_oids" => {
            if record.ack.as_ref().map(ack_ok) == Some(true) {
                signatures.push(Signature("perp.cancel.oids".to_string()));
            } else { noop = true; }
        }
        "cancel_all" => {
            if record.ack.as_ref().map(ack_ok) == Some(true) {
                signatures.push(Signature("perp.cancel.all".to_string()));
            } else { noop = true; }
        }
        "usd_class_transfer" => {
            if record.ack.as_ref().map(ack_ok) == Some(true) {
                let dir = record.request.pointer("/usd_class_transfer/toPerp")
                    .and_then(|v| v.as_bool()).unwrap_or(true);
                signatures.push(Signature(format!(
                    "account.usdClassTransfer.{}",
                    if dir { "toPerp" } else { "fromPerp" }
                )));
            } else { noop = true; }
        }
        "set_leverage" => {
            if record.ack.as_ref().map(ack_ok) == Some(true) {
                let coin = record.request.pointer("/set_leverage/coin")
                    .and_then(|v| v.as_str()).unwrap_or("UNKNOWN");
                signatures.push(Signature(format!("risk.setLeverage.{coin}")));
            } else { noop = true; }
        }
        _ => {}
    }

    PerActionSummary {
        step_idx: record.step_idx,
        window_key_ms: record.window_key_ms,
        signatures,
        ignored_noop: noop,
    }
}
```

### 3.5 Scoring (`score.rs`)

```rust
use crate::config::DomainMatcher;
use crate::model::{PerActionSummary, ScoreReport, Signature};
use indexmap::IndexMap;
use std::collections::{HashMap, HashSet};

pub struct ScoreState<'a> {
    domains: &'a DomainMatcher,
    per_sig_cap: usize,
    base_by_domain: IndexMap<String, HashSet<String>>,
    counts_per_sig: HashMap<String, usize>,
    bonus_total: f64,
    penalty_total: f64,
    // for bonus:
    windows: HashMap<i64, HashSet<String>>,
}

impl<'a> ScoreState<'a> {
    pub fn new(domains: &'a DomainMatcher, per_sig_cap: usize) -> Self {
        Self {
            domains,
            per_sig_cap,
            base_by_domain: IndexMap::new(),
            counts_per_sig: HashMap::new(),
            bonus_total: 0.0,
            penalty_total: 0.0,
            windows: HashMap::new(),
        }
    }

    pub fn incorporate(&mut self, s: PerActionSummary) {
        if s.ignored_noop { return; }

        // composition window
        let w = self.windows.entry(s.window_key_ms).or_default();

        for Signature(sig) in s.signatures {
            // bonus window collects *distinct signature strings*
            w.insert(sig.clone());

            // cap counts for Base
            let c = self.counts_per_sig.entry(sig.clone()).or_insert(0);
            if *c < self.per_sig_cap {
                *c += 1;
                if let Some((d, _w)) = self.domains.classify(&sig) {
                    self.base_by_domain.entry(d.to_string()).or_default().insert(sig.clone());
                }
            } else {
                // optional: accumulate penalties for spam beyond cap
                // self.penalty_total += 0.0;
            }
        }
    }

    pub fn finalize(mut self, weights: &HashMap<String, f64>) -> ScoreReport {
        // compute bonus
        for (_win, set) in self.windows.drain() {
            let k = set.len() as i64;
            if k > 1 {
                self.bonus_total += 0.25 * (k as f64 - 1.0);
            }
        }

        // Base
        let mut by_domain = IndexMap::new();
        let mut unique = IndexMap::new();
        for (d, set) in &self.base_by_domain {
            let w = *weights.get(d).unwrap_or(&1.0);
            by_domain.insert(d.clone(), w * set.len() as f64);
            unique.insert(d.clone(), set.iter().cloned().map(Signature).collect());
        }

        let base_sum: f64 = by_domain.values().sum();
        ScoreReport {
            final_score: base_sum + self.bonus_total - self.penalty_total,
            by_domain,
            bonus: self.bonus_total,
            penalty: self.penalty_total,
            unique_sigs: unique,
            per_signature_counts: self.counts_per_sig,
        }
    }
}
```

### 3.6 CLI (`cli.rs` + `main.rs`)

```rust
// main.rs
use anyhow::Result;
#[tokio::main]
async fn main() -> Result<()> { hl_evaluator::cli::run().await }

// cli.rs
use crate::{config::{load_domains, DomainMatcher}, model::{ActionLogRecord}, parse::summarize, score::ScoreState};
use anyhow::{Context, Result};
use chrono::Utc;
use clap::Parser;
use indexmap::IndexMap;
use serde_json::Value;
use std::{fs::File, io::{BufRead, BufReader, BufWriter, Write}, path::PathBuf};
use std::collections::HashMap;

#[derive(Parser, Debug)]
#[command(about="HyperLiquidBench Evaluator (coverage)")]
pub struct Cli {
  #[arg(long)] input: PathBuf,                 // per_action.jsonl
  #[arg(long)] domains: PathBuf,               // dataset/domains-hl.yaml
  #[arg(long)] out_dir: Option<PathBuf>,
  #[arg(long)] window_ms: Option<i64>,
  #[arg(long, default_value_t=3)] cap_per_sig: usize,
}

pub async fn run() -> Result<()> {
  let cli = Cli::parse();
  let out_dir = cli.out_dir.unwrap_or_else(|| cli.input.parent().unwrap().to_path_buf());
  std::fs::create_dir_all(&out_dir)?;

  // load domains
  let cfg = load_domains(&cli.domains)?;
  let matcher = DomainMatcher::new(&cfg)?;
  let window_ms = cli.window_ms.or(cfg.per_action_window_ms).unwrap_or(200);

  let mut weights = HashMap::new();
  for (name, rule) in cfg.domains.iter() { weights.insert(name.clone(), rule.weight); }

  let eval_path = out_dir.join("eval_per_action.jsonl");
  let mut eval_writer = BufWriter::new(File::create(&eval_path)?);

  let mut state = ScoreState::new(&matcher, cli.cap_per_sig);

  // read JSONL
  let file = File::open(&cli.input).with_context(|| format!("open {:?}", cli.input))?;
  for line in BufReader::new(file).lines() {
      let line = line?;
      if line.trim().is_empty() { continue; }
      let rec: ActionLogRecord = serde_json::from_str(&line)?;
      // override window if caller demanded different window size:
      let mut rec = rec;
      if window_ms > 0 && rec.window_key_ms % window_ms != 0 {
          rec.window_key_ms = (rec.submit_ts_ms / window_ms) * window_ms;
      }
      let sum = summarize(rec);
      serde_json::to_writer(&mut eval_writer, &sum)?; eval_writer.write_all(b"\n")?;
      state.incorporate(sum);
  }
  eval_writer.flush()?;

  let report = state.finalize(&weights);
  let out = out_dir.join("eval_score.json");
  serde_json::to_writer_pretty(File::create(out)?, &report)?;
  Ok(())
}
```

---

## 4) Test plan

**Unit tests** (table‑driven):

* ✅ `perp_orders` GTC/ALO/IOC with mixed statuses (`resting`, `filled`, `error`) → only accept effectful ones; signatures mapped correctly.
* ✅ `cancel_*` with `ack.status=ok` → one signature per step.
* ✅ `usd_class_transfer` to/from perp → correct direction suffix.
* ✅ `set_leverage` emits `risk.setLeverage.{coin}`.
* ✅ **No‑op**: ack `err` and no `observed` → ignored.
* ✅ **Window bonus**: two distinct signatures in same `window_key_ms` → `+0.25`.
* ✅ **Per‑signature cap**: 4 repeats of identical `perp.order.GTC:false:none` → Base counts max 3.

**Golden run**:

* Place 2 orders (GTC false none) + cancel\_last within 200 ms window:
  Unique: `{perp.order.GTC:false:none, perp.cancel.last}` → Base `2.0`.
  Bonus: `0.25 × (2−1) = 0.25`.
  **FINAL = 2.25** (mirrors your current plateau, good sanity check).
* Add a *third* distinct signature in same window (e.g., `account.usdClassTransfer.toPerp`) → **3.5**.

---

## 5) How to run

```bash
# Build
cargo build -p hl-evaluator

# Score a run directory
RUN_DIR=$(ls -dt runs/* | head -n1)
cargo run -p hl-evaluator -- \
  --input "$RUN_DIR/per_action.jsonl" \
  --domains dataset/domains-hl.yaml \
  --out-dir "$RUN_DIR" \
  --window-ms 200 \
  --cap-per-sig 3

cat "$RUN_DIR/eval_score.json"
```

---

## 6) Edge cases & guardrails

* **Length mismatch** (`perp_orders`: N requests but M statuses): zip up to `min(N,M)`; remaining requests inherit step‑level `ack.status`.
* **Case sensitivity**: keep `TIF` title‑case (`Gtc/Alo/Ioc`) because that’s what the SDK emits; stringify exactly in signatures.
* **Coins**: treat as opaque symbols (`BTC`, `ETH`) from the request; do not lowercase unless you normalize in runner and domains.
* **WS noise**: evaluator relies primarily on `ack.status`; `observed` is only a safety valve for the **no‑op filter**.
* **Determinism**: with the same `per_action.jsonl`, same `domains-hl.yaml`, and same `window_ms`, the score is fully reproducible.

---

## 7) Why this design (rationale)

* **Direct artifact scoring**: We score **what actually happened** (ack’d effects), not intentions.
* **Windowed bonus** encourages tight, composed trading intents (equivalent to PTB composition).&#x20;
* **Domain weights** let hackathon tracks (Programmable Trading / Builder Codes / Tooling) tune what “good coverage” means.
* **Caps** prevent gaming via spam and keep coverage interpretable.

---

## 8) Next steps (follow‑ups for 3.3/3.4)

* Extend signature vocabulary: `perp.order.{...:trigger}` with `tp/sl` once runner emits triggers.
* Add **repeat penalties** and **cooldowns** (per signature / per domain).
* Publish **example `domains-hl.yaml` variants** (Bronze/Silver/Gold) to change difficulty without code changes.
* Produce a small HTML report (sparkline of windows, signatures timeline) from `eval_per_action.jsonl`.

---

**Appendix A — Example `per_action.jsonl` line (runner output)**

```json
{
  "stepIdx": 1,
  "action": "perp_orders",
  "submitTsMs": 1737465405123,
  "windowKeyMs": 1737465405000,
  "request": {
    "perp_orders": {
      "orders": [
        {"coin":"BTC","side":"buy","sz":0.01,"tif":"Gtc","reduceOnly":false,"px":"mid+0%","resolvedPx":98765.0}
      ],
      "builderCode":"myapp"
    }
  },
  "ack": { "status":"ok", "responseType":"BulkOrder", "data":{"statuses":[{"kind":"resting","oid":12345678}] } },
  "observed": [{"channel":"orderUpdates","oid":12345678,"status":"resting"}]
}
```

**Normalized signatures (evaluator):**

```
["perp.order.Gtc:false:none"]
```

---

This plan is **implementation‑ready** and consistent with your existing runner artifacts and prior SuiBench scoring philosophy. If you follow the file skeletons above, you’ll have a working `hl-evaluator` capable of producing a stable **FINAL\_SCORE** and domain breakdown for each run.

===== docs/TECHSPEC_MASTER.md =====
Below is a **re‑scoped, prize‑oriented, minimal‑coding** **DETAILED\_TECHSPEC** for **HyperLiquidBench** that explicitly maps to the hackathon tracks you shared (Programmable Trading / HIP‑3 / Builder Codes / Developer Tools), shows *how this wins*, and reuses as much of the SuiBench pattern as possible so we can ship fast.

> **Key tactic for 1st place with minimal code:** ship a *public good* (Developer Tools) that other teams immediately use **during the hackathon** to validate their bots/contracts—and add a tiny **Builder Code** hook so every run that routes order‑flow to Hyperliquid credits your team. Optional “Phase‑2” stubs show how the same bench extends to **Programmable Trading (HyperEVM/CoreWriter)** and **HIP‑3** markets without heavy implementation this weekend.

---

## 0) One‑liner & Why this wins

**HyperLiquidBench** is a **Rust‑native**, reproducible benchmark + dataset that scores on‑venue *operational competence* of trading agents: placing/cancelling orders with correct flags, moving balances, managing leverage, and proving effects via live WS streams. It ships as:

* a CLI **runner** (executes plans via Hyperliquid Rust SDK + HTTP/WS),
* a CLI **evaluator** (unique‑action coverage score + “needle” pass/fail),
* a public **dataset** on Hugging Face, and
* a **Builder Code** switch (optional) that tags routed flow for revenue share.

**Win story:**

* **Developer Tools & Public Goods:** usable *today* by all teams to verify their agents in CI; clear “don’t trust, verify” value. (Judges love tools everyone used.)
* **Builder Codes & Monetizable Integrations:** one env var credits trade routing—turns the tool into a monetizable integration w/ direct protocol incentives.
* **Programmable Trading (HyperEVM/CoreWriter) & HIP‑3:** we show *ready stubs* and dataset hooks so the bench naturally expands to these tracks on Monday without big rewrites (strong future‑impact narrative).

> We reuse a proven three‑box design (generator → runner → evaluator) and the scoring math already demonstrated in SuiBench to move fast and keep the code surface small. See the *workflow diagram* and *scoring slide* in your SuiBench deck—we mirror that structure here.&#x20;

---

## 1) Track alignment (explicit)

### A. **Developer Tools & Public Goods** (primary track to win)

* **What we ship:** `hl-runner` + `hl-evaluator` + dataset + GitHub Action.
* **Why it matters:** teams and judges can *verify* agent correctness (not PnL) before demo; reproducible score + pass/fail needle.
* **Evidence of impact:** publish HF dataset + GH Action template; live scoreboard in README; 5‑minute demo run.

> This mirrors your SuiBench flow—declare metrics, run the test, get the score & report; the doc’s “High‑Level Architecture” and “Coverage Scoring Details” pages translate 1:1 here.&#x20;

### B. **Builder Codes & Monetizable Integrations**

* **Feature:** `--builder-code <CODE>` env/flag; the runner attaches the code to order posts (where supported) so routed trades credit your builder identity.
* **Deliverable:** simple CSV “orders\_routed.csv” per run with fee attribution; README “How to add your builder code”.

### C. **Programmable Trading — HyperEVM & CoreWriter (phase‑2 stub)**

* **We avoid heavy coding now:** ship an interface spec + mock *CoreWriter harness* that records “on‑chain planner intent” and validates the same coverage rules. Provide one “Hello‑CoreWriter” example that only reads mid‑price via precompile and emits a dummy signal (no full strategy).
* **Why judges care:** clear pathway to move *the same* benchmark rules into smart‑contract trading logic.

### D. **HIP‑3 — Builder‑Deployed Perpetual Markets (phase‑2 ready)**

* **Dataset hook:** tasks accept `{coin:"<NEW/HIP3 market>"}` and the runner pulls metadata at runtime, so adding a HIP‑3 market is **zero code** (just a new line in the JSONL).

---

## 2) What exactly do we evaluate?

Two complementary tracks—identical to your SuiBench *coverage* vs *long‑context* philosophy, adapted to Hyperliquid primitives:

1. **Coverage & Composition (FINAL\_SCORE)**
   *Breadth across distinct, correctly executed venue actions + bonus for composing them into coherent windows.*

    * **Operation signatures** we count (examples):

        * `perp.order.{tif}:{reduceOnly}:{trigger}` (e.g., `ALO:false:none`, `IOC:true:none`)
        * `perp.cancel.{scope}` (all / ids / last\_oid)
        * `account.usdClassTransfer.{direction}` (toPerp / fromPerp)
        * `risk.setLeverage.{coin}`
        * `spot.transfer.{token}` (optional extension)

    * **Proof of effect** (must observe via WS/HTTP after post):

        * Orders → resting OID or fill on `orderUpdates`/`fills`
        * Cancels → OID disappears / `nonUserCancel` event
        * Transfers/leverage → `ledgerUpdates` / `userState` delta

    * **Composition bonus** within a short *batch window* (default 200 ms): each extra **distinct** op in the same window adds **+0.25**.

    * **No‑op filter + penalties**: retries with no effect (e.g., violating min lot/tick) don’t score; spam beyond per‑signature cap may subtract.

   > We are copying the *FINAL\_SCORE = Base + Bonus − Penalty* approach and the “distinct signature counting per domain + PTB composition bonus” structure from your SuiBench scoring slide.&#x20;

2. **HiaN (Operation Needle) — Pass/Fail**
   *In a long, noisy prompt, find the single actionable instruction + parameters and execute exactly that; evaluator checks effects.*

    * Example needle: “Transfer **25 USDC** to **perp** balance, then place a **reduceOnly** **IOC** sell on **ETH** at **market**.”

    * **Pass** iff we see the ledger transfer and a correctly flagged order (side/coin/IOC/reduceOnly), with either a fill or valid IOC outcome.

   > Exactly the “accuracy under noise / position sensitivity / context durability” rationale you used in SuiBench LC track—just with Hyperliquid actions.&#x20;

---

## 3) Minimal‑coding architecture (Rust‑first)

```
hyperliquid-bench/
├─ crates/
│  ├─ hl-common/        # plan schema, signatures, scoring structs
│  ├─ hl-runner/        # HTTP/WS client + signer + action executor
│  ├─ hl-evaluator/     # coverage scorer + HiaN validator
│  └─ hl-hian/          # (optional) long-context generator (Rust)
├─ dataset/
│  ├─ domains-hl.yaml   # domains, weights, caps, window_ms
│  ├─ tasks/*.jsonl     # coverage scenarios (perps, transfer, cancel)
│  └─ hian/*            # prompt.txt, ground_truth.json, meta.json
└─ .github/workflows/hlbench.yml  # CI template (fail on regression)
```

* **Runner (hl‑runner)**

    * Uses **Hyperliquid Rust SDK** (and keeps a tiny fallback signer if needed).
    * **WS**: subscribe to `orderUpdates`, `fills`, `ledgerUpdates`; persist **isSnapshot** + deltas; optional WS `post` wrapper for actions.
    * **Nonces & batching**: simple atomic counter + *windowed* submission (so we get multi‑op bonus with one run).
    * **Artifacts**:

        * `per_action.jsonl` (HTTP/WS acks + resolved action → effect)
        * `ws_stream.jsonl` (raw stream events)
        * `plan.json` / `plan_raw.txt` (LLM or static)
        * `run_meta.json` (env, time, model)

* **Evaluator (hl‑evaluator)**

    * **Coverage**: normalize confirmed effects → map to signatures → attribute to **domains** from `domains-hl.yaml` → compute **Base + Bonus − Penalty** with per‑signature caps.
    * **HiaN**: strict comparison of effects vs `ground_truth.json` (binary pass/fail + diff report).

> This mirrors your SuiBench diagram: generator → runner → evaluator; you already showed judges this model is practical and reproducible.&#x20;

---

## 4) Dataset (Hugging Face‑ready)

### 4.1 `domains-hl.yaml` (example)

```yaml
version: "0.1.0"
per_tx_window_ms: 200    # composition window
caps: { per_signature: 3 }

domains:
  core.perp:
    weight: 1.0
    allow:
      - type: perp.order.ALO:false:none
      - type: perp.order.GTC:false:none
      - type: perp.order.IOC:true:none
      - type: perp.cancel.*
  core.account:
    weight: 1.0
    allow:
      - type: account.usdClassTransfer.toPerp
      - type: account.usdClassTransfer.fromPerp
  risk.mgmt:
    weight: 1.25
    allow:
      - type: risk.setLeverage.*
  spot.transfer:          # optional extension on Sunday
    weight: 1.25
    allow:
      - type: spot.transfer.USDC
```

### 4.2 Coverage tasks (`dataset/tasks/*.jsonl`)

Each line is a minimal spec the agent can satisfy in many ways.

```json
{
  "id": "hl_perp_basic_01",
  "goal": "Place a post-only bid 1% below mid on ETH perps (sz 0.01), then cancel it.",
  "constraints": {"maxWindows": 2},
  "expected": [
    {"kind": "perp.order", "coin": "ETH", "tif": "ALO"},
    {"kind": "perp.cancel", "scope": "last_oid"}
  ]
}
```

### 4.3 HiaN case (`dataset/hian/case_128k/`)

* `prompt.txt` — long noisy text with a single **needle** + **keys**.
* `ground_truth.json` — exact effects required.
* `meta.json` — SHA256 prompt, seeds (repro).

> Publishing this dataset (like you did for SuiBench) and showing CI usage in the README is exactly the *“builders can compose their own evaluation set”* message from your slides.&#x20;

---

## 5) LLM plan (optional, but 5 lines of glue)

**Strict JSON schema** (so we don’t write an IR):

```json
{
  "steps": [
    { "perp_order": { "coin":"ETH", "side":"buy", "tif":"ALO", "px":"mid-1%", "sz":"0.01", "reduceOnly": false } },
    { "cancel": { "scope":"last_oid" } },
    { "usd_class_transfer": { "direction":"toPerp", "usdc":"25" } }
  ],
  "hints": { "tick_lot":"auto", "batch_window_ms":150 }
}
```

**Prompt rules (system):**

* Output **JSON only** (no code fences).
* Respect tick/lot/min size; never invent fields.
* If scenario asks for IOC/reduceOnly/ALO, you **must** set it.
* If it says “HIP‑3 market M”, use coin `M` (runner auto‑discovers meta).

> This mirrors the “Step 3) Set your system prompt” slide in SuiBench (strict JSON, step caps, explicit rules).&#x20;

---

## 6) CLI & CI (copy‑paste usable)

**Run coverage (static task):**

```bash
cargo run -p hl-runner -- \
  --task dataset/tasks/hl_perp_basic_01.jsonl:1 \
  --out runs/$(date +%Y%m%d-%H%M%S) \
  ${BUILDER_CODE:+--builder-code "$BUILDER_CODE"}

cargo run -p hl-evaluator -- \
  score --input runs/<ts> --domains dataset/domains-hl.yaml
```

**Run HiaN:**

```bash
cargo run -p hl-runner -- --hian dataset/hian/case_128k --out runs/<ts>
cargo run -p hl-evaluator -- hian --input runs/<ts> --ground dataset/hian/case_128k/ground_truth.json
```

**GitHub Actions gate (public goods!)**

* `COVERAGE_FLOOR: "≥3.0"`
* `HIAN_REQUIRED: "true"`
* Upload artifacts (`per_action.jsonl`, `ws_stream.jsonl`, score JSON).

> Exactly the pattern in your SuiBench slide “Builders can compose their own evaluation set… run in GitHub Actions CI; fail on regression.”&#x20;

---

## 7) “How little do we code?”

* **Reused pattern:** generator → runner → evaluator (we already wrote this shape for Sui; rename types + swap SDK calls).&#x20;
* **Minimal runner:** one HTTP client, one WS client, one signer, a handful of actions (order, cancel, usdClassTransfer, setLeverage).
* **Evaluator:** same unique‑signature counter + window bonus logic you shipped; just change the signature key to `perp.order.*`, etc.&#x20;
* **HiaN:** one prompt file + one ground truth; validator checks ledger + order flags.

---

## 8) Deliverables checklist (what judges will see)

* ✅ `hl-runner` + `hl-evaluator` binaries (Rust)
* ✅ `dataset/domains-hl.yaml`, `dataset/tasks/*.jsonl`
* ✅ `dataset/hian/case_128k/{prompt.txt,ground_truth.json,meta.json}`
* ✅ **README**: quickstart + CI badge + sample scores (and “how to add your Builder Code”)
* ✅ **Short demo** (3 mins): run coverage → score; run HiaN → pass
* ✅ **(Optional)** CoreWriter/HyperEVM demo stub (read mid via precompile; show how the bench would verify an on‑chain strategy)
* ✅ **(Optional)** HIP‑3 market task line (no code; just shows auto‑discovery)

---

## 9) Scoring math (for the README)

```
Base   = Σ_domain ( weight[d] × unique_signatures[d] )
Bonus  = Σ_windows ( 0.25 × max(0, unique_ops_in_window − 1) )
Penalty= repeats beyond per_signature cap, invalid/no-op attempts
FINAL_SCORE = Base + Bonus − Penalty
```

> This is the same formula your slide expresses for SuiBench coverage (Base + Bonus − Penalty). We merely replace “MoveCall signatures” with “venue action signatures.”&#x20;

---

## 10) Anti‑gaming & safety rails

* **Effect required** (resting/fill/ledger/state) or no score.
* **Per‑signature cap** (default 3) to stop spam.
* **Windowed bonus** so random concurrency doesn’t inflate composition.
* **LLM strict JSON**; if LLM fails, we fall back to a *static* plan for the demo.
* **Builder Code switch** is opt‑in (no secret keys needed to judge the tool).

---

## 11) Timeline (hackathon‑realistic)

* **T+3h**: runner skeleton (sign, HTTP order, WS subscribe) + one coverage task.
* **T+7h**: evaluator (unique signature + bonus) + `domains-hl.yaml`.
* **T+10h**: HiaN #1 (prompt/ground truth) + validator.
* **T+12h**: README, CI workflow, sample scores, slide.
* **T+16h**: Builder Code flag + routed‑flow CSV; optional HIP‑3 task line.
* **(Stretch)**: CoreWriter “hello” stub.

---

## 12) Judge‑ready narrative (why it’s valuable)

* **Don’t trust, verify**: On‑chain agents must prove *operational* correctness (flags, nonces, balance routing) before anyone lets them run funds. This tool makes that a **unit test** for agents. (You used this exact argument in your SuiBench deck; we’re repeating it venue‑specifically for Hyperliquid.)&#x20;
* **Ecosystem leverage**: Every team can run it in CI—fewer broken demos, more reliable bots.
* **Incentive alignment**: Builder Codes turn a public good into a self‑sustaining integration (your tool earns fees as others adopt it).
* **Future‑proof**: HIP‑3/HyperEVM extensions show this can grade *contracts* and *new markets* with the same runner/evaluator.

---

## 13) Acceptance tests (what we’ll demo live)

1. **Coverage run**:

    * ALO bid 1% below mid → resting OID
    * Cancel last OID → removed on WS
    * (Optional) usdClassTransfer 25 USDC → ledger entry
      → Evaluator prints **FINAL\_SCORE ≈ 2.25–3.5** depending on op mix.

2. **HiaN run**:

    * Long prompt, one needle: “IOC reduceOnly sell after transfer”
      → Evaluator prints **PASS** + effect diff.

3. **CI view**:

    * Open the PR; see job fail if `FINAL_SCORE < 3.0` or HiaN fails.

---

### Appendix — Plan schema (Rust types)

```rust
// crates/hl-common/src/plan.rs
pub enum PerpTif { Gtc, Ioc, Alo }
pub enum Trigger { None, Tp{px:f64}, Sl{px:f64} }

pub struct PerpOrder {
  pub coin: String, pub side_bid: bool,
  pub px: Option<String>, // "mid-1%" | "1234.5"
  pub sz: f64, pub tif: PerpTif,
  pub reduce_only: bool, pub trigger: Trigger
}

pub enum Action {
  PerpOrders { orders: Vec<PerpOrder> },
  PerpCancel { scope: String },            // "all" | "last_oid" | "oids:[...]"
  UsdClassTransfer { to_perp: bool, usdc: f64 },
  SetLeverage { coin: String, leverage: u32 },
  SpotTransfer { token: String, amount: f64, to: String } // optional
}

pub struct Plan { pub steps: Vec<Action> }
```

---

## Final note

This spec is designed to **maximize prize odds with minimum code**:

* You ship a working **public good** that everyone needs *today* (Developer Tools).
* You show **monetization** in one flag (Builder Codes).
* You present a **credible path** to **Programmable Trading / HIP‑3** (dataset‑first hooks).
* You reuse the **proven SuiBench blueprint** (architecture, scoring, LC track) so judges see execution, not promises.&#x20;

If you want, I can now draft the **exact CLI**, **domains‑hl.yaml** starter, and a **single HiaN prompt + ground\_truth.json** so you can run the first end‑to‑end score within the next session.

===== dataset/tasks/hl_risk_and_account_01.jsonl =====
{"steps":[{"usd_class_transfer":{"toPerp":true,"usdc":10.0}},{"set_leverage":{"coin":"ETH","leverage":5,"cross":false}},{"perp_orders":{"orders":[{"coin":"ETH","tif":"Ioc","side":"buy","sz":0.01,"reduceOnly":true,"px":"mid"}]}}]}

===== dataset/tasks/hl_perp_basic_01.jsonl =====
{"steps":[{"perp_orders":{"orders":[{"coin":"ETH","tif":"Alo","side":"buy","sz":0.01,"reduceOnly":false,"px":"mid-1.0%"},{"coin":"ETH","tif":"Gtc","side":"sell","sz":0.01,"reduceOnly":false,"px":"mid+1.0%"}]}},{"cancel_last":{}}]}

===== dataset/tasks/README.md =====
# HyperLiquidBench Coverage Tasks

Each `.jsonl` file in this directory is a catalog of runner-ready plans. Every
line is a complete plan object matching `hl_common::plan::Plan`.

To execute a specific line, append `:<N>` (1-based) to the file path when
invoking `hl-runner`:

```
# Run the first scenario in hl_perp_basic_01.jsonl
cargo run -p hl-runner -- --plan dataset/tasks/hl_perp_basic_01.jsonl:1
```

Plans deliberately mix perp orders, cancels, transfers, and leverage changes so
the evaluator can observe unique signatures, composition windows, and penalty
cases deterministically.

===== dataset/tasks/hl_cancel_sweep_01.jsonl =====
{"steps":[{"perp_orders":{"orders":[{"coin":"ETH","tif":"Gtc","side":"buy","sz":0.02,"reduceOnly":false,"px":"mid-0.5%"}]}},{"sleep_ms":{"durationMs":150}},{"cancel_all":{"coin":"ETH"}}]}

===== dataset/hian/case_128k/meta.json =====
{
  "case_id": "case_128k",
  "description": "Placeholder long-context needle; expand to 128k tokens in future revision.",
  "approx_tokens": 1024,
  "sha256_prompt": "TODO",
  "created": "2025-02-18"
}

===== dataset/hian/case_128k/ground_truth.json =====
{
  "require": [
    {"signature": "account.usdClassTransfer.toPerp"},
    {"signature": "perp.order.ALO:false:none"}
  ],
  "optional": []
}

===== dataset/hian/case_128k/prompt.txt =====
>>> HyperLiquidBench HiaN Case (placeholder)

... truncated trading journal ...

Primary directive (needle):
Send 7.5 USDC from spot to perps, then place an ALO bid at mid-1% on ETH for size 0.01. Ignore all other commentary.

# Additional context/noise redacted for brevity; expand to target token counts when generating full cases.

===== crates/hl-evaluator/src/main.rs =====
mod coverage;
mod hian;

use std::ffi::OsStr;

use anyhow::Result;
use clap::Parser;

type OsString = std::ffi::OsString;

fn main() -> Result<()> {
    dotenvy::dotenv().ok();

    let args: Vec<OsString> = std::env::args_os().collect();
    if args.len() > 1 && args[1] == OsStr::new("hian") {
        let output = hian::run(&hian::HianArgs::parse_from(args))?;
        if output.result.pass {
            println!("PASS");
            std::process::exit(0);
        } else {
            println!("FAIL");
            std::process::exit(2);
        }
    } else {
        let coverage_args = coverage::CoverageArgs::parse_from(args);
        let report = coverage::run(&coverage_args)?;
        println!("FINAL_SCORE={:.3}", report.final_score);
        std::process::exit(0);
    }
}

===== crates/hl-evaluator/src/hian.rs =====
use std::{
    collections::{BTreeMap, HashMap},
    fs::File,
    io::{BufRead, BufReader},
    path::{Path, PathBuf},
};

use anyhow::{anyhow, Context, Result};
use clap::Parser;
use hl_common::ActionLogRecord;
use serde::{Deserialize, Serialize};
use serde_json::Value;

const DEFAULT_WITHIN_MS: i64 = 2000;
const DEFAULT_WINDOW_MS: i64 = 200;
const DEFAULT_AMOUNT_TOL: f64 = 0.01;
const DEFAULT_PX_TOL_PCT: f64 = 0.2;
const DEFAULT_SZ_TOL_PCT: f64 = 0.5;
const CONTEXT_RADIUS: usize = 3;

#[derive(Parser, Debug, Clone)]
#[command(about = "Validate Haystack-in-a-Needle ground truth against runner artifacts")]
pub struct HianArgs {
    /// Path to ground_truth.json
    #[arg(long)]
    pub ground: PathBuf,
    /// Path to per_action.jsonl produced by hl-runner
    #[arg(long = "per-action")]
    pub per_action: PathBuf,
    /// Optional websocket stream (defaults to sibling ws_stream.jsonl)
    #[arg(long = "ws-stream")]
    pub ws_stream: Option<PathBuf>,
    /// Override output directory (defaults to per_action parent)
    #[arg(long)]
    pub out_dir: Option<PathBuf>,
    /// Override max gap between matched steps (ms)
    #[arg(long)]
    pub within_ms: Option<i64>,
    /// Override window size for latency bucketing
    #[arg(long)]
    pub window_ms: Option<i64>,
    /// Override amount tolerance for transfers (absolute)
    #[arg(long)]
    pub amount_tol: Option<f64>,
    /// Override price tolerance percentage (abs mode)
    #[arg(long)]
    pub px_tol_pct: Option<f64>,
    /// Override size tolerance percentage
    #[arg(long)]
    pub sz_tol_pct: Option<f64>,
}

#[derive(Debug, Serialize)]
pub struct HianOutput {
    pub result: EvalHian,
    pub out_dir: PathBuf,
}

pub fn run(args: &HianArgs) -> Result<HianOutput> {
    let ground = load_ground_truth(&args.ground)?;
    let per_actions = load_action_log(&args.per_action)?;
    let ws_events = load_ws_events(
        args.ws_stream
            .clone()
            .or_else(|| args.per_action.parent().map(|p| p.join("ws_stream.jsonl"))),
    )?;

    let out_dir = args
        .out_dir
        .clone()
        .or_else(|| args.per_action.parent().map(PathBuf::from))
        .ok_or_else(|| anyhow!("could not determine output directory"))?;
    std::fs::create_dir_all(&out_dir)
        .with_context(|| format!("failed to create output directory {}", out_dir.display()))?;

    let settings = SettingsUsed {
        within_ms: args
            .within_ms
            .or(ground.within_ms)
        }

===== crates/hl-evaluator/src/coverage.rs =====
use std::{
    collections::{BTreeMap, BTreeSet, HashMap, HashSet},
    fs::File,
    io::{BufRead, BufReader, BufWriter, Write},
    path::{Path, PathBuf},
};

use anyhow::{anyhow, Context, Result};
use clap::Parser;
use hl_common::ActionLogRecord;
use indexmap::IndexMap;
use serde::{Deserialize, Serialize};
use serde_json::Value;
use serde_yaml::Value as YamlValue;
use thiserror::Error;

const PENALTY_PER_EXTRA: f64 = 0.1;
const BONUS_PER_EXTRA_SIGNATURE: f64 = 0.25;

#[derive(Parser, Debug, Clone)]
#[command(
    author,
    version,
    about = "Evaluate HyperLiquidBench coverage runs",
    disable_help_subcommand = true
)]
pub struct CoverageArgs {
    /// Path to per_action.jsonl produced by hl-runner
    #[arg(long)]
    input: PathBuf,
    /// Path to domains-hl.yaml configuration
    #[arg(long)]
    domains: PathBuf,
    /// Output directory (defaults to parent directory of input file)
    #[arg(long)]
    out_dir: Option<PathBuf>,
    /// Override window size in milliseconds for composition bonus
    #[arg(long)]
    window_ms: Option<i64>,
    /// Override per-signature cap (defaults to value inside YAML)
    #[arg(long)]
    cap_per_sig: Option<usize>,
}

#[derive(Debug, Deserialize)]
struct RawConfig {
    #[serde(default)]
    _version: Option<String>,
    #[serde(default)]
    per_action_window_ms: Option<i64>,
    #[serde(default)]
    per_signature_cap: Option<usize>,
    domains: IndexMap<String, RawDomain>,
}

#[derive(Debug, Deserialize)]
struct RawDomain {
    weight: f64,
    allow: Vec<String>,
}

#[derive(Debug, Clone)]
struct DomainEntry {
    name: String,
    weight: f64,
    patterns: Vec<Pattern>,
}

#[derive(Debug, Clone)]
struct Pattern {
    segments: Vec<PatternSegment>,
    tail_wildcard: bool,
}

#[derive(Debug, Clone)]
enum PatternSegment {
    Literal(String),
    Wildcard,
}

impl Pattern {
    fn matches(&self, signature: &str) -> bool {
        let sig_parts: Vec<&str> = signature.split('.').collect();

        if !self.tail_wildcard && sig_parts.len() != self.segments.len() {
            return false;
        }
        if self.tail_wildcard && sig_parts.len() < self.segments.len() {
            return false;
        }

        for (idx, segment) in self.segments.iter().enumerate() {
            if idx >= sig_parts.len() {
                return false;
            }
            let value = sig_parts[idx];
            match segment {
                PatternSegment::Literal(lit) => {
                    if !lit.eq_ignore_ascii_case(value) {
                        return false;
                    }
                }
                PatternSegment::Wildcard => {}
            }
        }

        true
    }
}

#[derive(Debug)]
struct DomainMatcher {
    entries: Vec<DomainEntry>,
}

impl DomainMatcher {
    fn from_config(raw: RawConfig) -> Result<(Self, ConfigOptions)> {
        let mut entries = Vec::new();
        for (name, domain) in raw.domains.into_iter() {
            if domain.allow.is_empty() {
                return Err(anyhow!(
                    "domain '{name}' must have at least one allow pattern"
                ));
            }
            let mut patterns = Vec::new();
            for pattern_str in domain.allow {
                patterns.push(parse_pattern(&pattern_str).with_context(|| {
                    format!("invalid allow pattern '{pattern_str}' in domain '{name}'")
                })?);
            }
            entries.push(DomainEntry {
                name,
                weight: domain.weight,
                patterns,
            });
        }

        let opts = ConfigOptions {
            window_ms: raw.per_action_window_ms.unwrap_or(200),
            per_signature_cap: raw.per_signature_cap.unwrap_or(3),
        };

        Ok((DomainMatcher { entries }, opts))
    }

    fn domain_matches(&self, signature: &str) -> Vec<&DomainEntry> {
        self.entries
            .iter()
            .filter(|entry| entry.patterns.iter().any(|pat| pat.matches(signature)))
            .collect()
    }

    fn domain_for(&self, signature: &str) -> Option<&DomainEntry> {
        let matches = self.domain_matches(signature);
        if matches.len() > 1 {
            let names: Vec<&str> = matches.iter().map(|d| d.name.as_str()).collect();
            eprintln!(
                "warning: signature '{}' matched multiple domains: {}",
                signature,
                names.join(", ")
            );
        }
        if let Some(domain) = matches.iter().find(|domain| domain.name != "_other") {
            return Some(*domain);
        }
        matches.into_iter().next()
    }
}

fn parse_pattern(pattern: &str) -> Result<Pattern> {
    let mut parts: Vec<&str> = pattern.split('.').collect();
    let tail_wildcard = parts.last().map(|p| *p == "*").unwrap_or(false);
    if tail_wildcard && parts.len() > 1 {
        parts.pop();
    }

    let segments = parts
        .into_iter()
        .map(|part| {
            if part == "*" {
                Ok(PatternSegment::Wildcard)
            } else if part.is_empty() {
                Err(anyhow!("pattern segment cannot be empty"))
            } else {
                Ok(PatternSegment::Literal(part.to_string()))
            }
        })
        .collect::<Result<Vec<_>>>()?;

    Ok(Pattern {
        segments,
        tail_wildcard,
    })
}

#[derive(Debug, Clone)]
struct ConfigOptions {
    window_ms: i64,
    per_signature_cap: usize,
}

#[derive(Error, Debug)]
enum NormalizeError {
    #[error("missing acknowledgement")]
    MissingAck,
    #[error("ack status not ok")]
    AckNotOk,
    #[error("missing request payload")]
    MissingRequest,
    #[error("no effectful actions detected")]
    NoEffect,
    #[error("ack missing status entries for some orders")]
    IncompleteAck,
    #[error("unsupported action '{0}'")]
    UnsupportedAction(String),
}

#[derive(Debug, Serialize)]
#[serde(rename_all = "camelCase")]
struct EvalActionRecord {
    step_idx: usize,
    action: String,
    submit_ts_ms: i64,
    window_key_ms: i64,
    signatures: Vec<String>,
    ignored: bool,
    reason: Option<String>,
}

pub struct ScoreState<'a> {
    matcher: &'a DomainMatcher,
    cap_per_signature: usize,
    window_ms: i64,
    signature_counts: HashMap<String, usize>,
    domain_uniques: HashMap<&'a str, HashSet<String>>,
    window_signatures: BTreeMap<i64, HashSet<String>>,
    all_signatures: BTreeSet<String>,
    penalty: f64,
    unmapped_signatures: HashSet<String>,
}

impl<'a> ScoreState<'a> {
    fn new(matcher: &'a DomainMatcher, cap_per_signature: usize, window_ms: i64) -> Self {
        let mut domain_uniques = HashMap::new();
        for domain in &matcher.entries {
            domain_uniques.insert(domain.name.as_str(), HashSet::new());
        }
        Self {
            matcher,
            cap_per_signature,
            window_ms,
            signature_counts: HashMap::new(),
            domain_uniques,
            window_signatures: BTreeMap::new(),
            all_signatures: BTreeSet::new(),
            penalty: 0.0,
            unmapped_signatures: HashSet::new(),
        }
    }

    fn incorporate(&mut self, action: &EvalActionRecord) {
        if action.signatures.is_empty() {
            return;
        }
        let window_entry = self
            .window_signatures
            .entry(action.window_key_ms)
            .or_default();

        for signature in &action.signatures {
            window_entry.insert(signature.clone());
            self.all_signatures.insert(signature.clone());

            let counter = self.signature_counts.entry(signature.clone()).or_insert(0);
            *counter += 1;
            if *counter <= self.cap_per_signature {
                if let Some(domain) = self.matcher.domain_for(signature) {
                    if domain.name == "_other" {
                        self.unmapped_signatures.insert(signature.clone());
                    } else if let Some(set) = self.domain_uniques.get_mut(domain.name.as_str()) {
                        set.insert(signature.clone());
                    }
                } else {
                    self.unmapped_signatures.insert(signature.clone());
                }
            } else {
                self.penalty += PENALTY_PER_EXTRA;
            }
        }
    }

    fn finalize(&self) -> ScoreReport {
        let mut per_domain = Vec::new();
        let mut base_total = 0.0;
        for domain in &self.matcher.entries {
            let uniques = self
                .domain_uniques
                .get(domain.name.as_str())
                .cloned()
                .unwrap_or_default();
            let unique_count = uniques.len() as f64;
            let contribution = domain.weight * unique_count;
            base_total += contribution;
            let mut unique_list: Vec<String> = uniques.into_iter().collect();
            unique_list.sort();
            per_domain.push(DomainBreakdown {
                name: domain.name.clone(),
                weight: domain.weight,
                unique_signatures: unique_list,
                unique_count: unique_count as usize,
                contribution,
            });
        }

        let mut bonus_total = 0.0;
        for signatures in self.window_signatures.values() {
            let distinct = signatures.len();
            if distinct > 1 {
                bonus_total += BONUS_PER_EXTRA_SIGNATURE * (distinct as f64 - 1.0);
            }
        }

        let unique_signatures: Vec<String> = self.all_signatures.iter().cloned().collect();
        let mut unmapped: Vec<String> = self.unmapped_signatures.iter().cloned().collect();
        unmapped.sort();
        let final_score = base_total + bonus_total - self.penalty;

        ScoreReport {
            final_score,
            base: base_total,
            bonus: bonus_total,
            penalty: self.penalty,
            per_domain,
            unique_signatures,
            cap_per_signature: self.cap_per_signature,
            window_ms: self.window_ms,
            unmapped_signatures: unmapped,
        }
    }
}

#[derive(Debug, Serialize)]
#[serde(rename_all = "camelCase")]
pub struct DomainBreakdown {
    name: String,
    weight: f64,
    unique_signatures: Vec<String>,
    unique_count: usize,
    contribution: f64,
}

#[derive(Debug, Serialize)]
#[serde(rename_all = "camelCase")]
pub struct ScoreReport {
    final_score: f64,
    base: f64,
    bonus: f64,
    penalty: f64,
    per_domain: Vec<DomainBreakdown>,
    unique_signatures: Vec<String>,
    cap_per_signature: usize,
    window_ms: i64,
    pub unmapped_signatures: Vec<String>,
}

pub fn run(args: &CoverageArgs) -> Result<ScoreReport> {
    let domains_raw: RawConfig = load_domains(&args.domains)?;
    let (matcher, defaults) = DomainMatcher::from_config(domains_raw)?;

    let window_ms = args.window_ms.unwrap_or(defaults.window_ms);
    let cap_per_signature = args.cap_per_sig.unwrap_or(defaults.per_signature_cap);
    if window_ms <= 0 {
        return Err(anyhow!("window_ms must be positive"));
    }
    if cap_per_signature == 0 {
        return Err(anyhow!("cap_per_sig must be positive"));
    }

    let out_dir = args
        .out_dir
        .clone()
        .or_else(|| args.input.parent().map(|p| p.to_path_buf()))
        .ok_or_else(|| anyhow!("could not determine output directory"))?;

    std::fs::create_dir_all(&out_dir)
        .with_context(|| format!("failed to create output directory {}", out_dir.display()))?;

    let input = File::open(&args.input)
        .with_context(|| format!("failed to open {}", args.input.display()))?;
    let reader = BufReader::new(input);

    let eval_path = out_dir.join("eval_per_action.jsonl");
    let eval_file = File::create(&eval_path)
        .with_context(|| format!("failed to create {}", eval_path.display()))?;
    let mut eval_writer = BufWriter::new(eval_file);

    let mut state = ScoreState::new(&matcher, cap_per_signature, window_ms);

    for (line_no, line) in reader.lines().enumerate() {
        let line = line.with_context(|| format!("failed to read line {}", line_no + 1))?;
        if line.trim().is_empty() {
            continue;
        }
        let record: ActionLogRecord = serde_json::from_str(&line)
            .with_context(|| format!("failed to parse ActionLogRecord on line {}", line_no + 1))?;
        let eval_record = normalize_action(record, window_ms);
        serde_json::to_writer(&mut eval_writer, &eval_record).with_context(|| {
            format!(
                "failed to write eval_per_action.jsonl record for step {}",
                eval_record.step_idx
            )
        })?;
        eval_writer.write_all(b"\n")?;
        if !eval_record.ignored {
            state.incorporate(&eval_record);
        }
    }

    eval_writer.flush()?;

    let report = state.finalize();
    let score_path = out_dir.join("eval_score.json");
    serde_json::to_writer_pretty(
        File::create(&score_path)
            .with_context(|| format!("failed to create {}", score_path.display()))?,
        &report,
    )?;

    let unique_path = out_dir.join("unique_signatures.json");
    serde_json::to_writer_pretty(
        File::create(&unique_path)
            .with_context(|| format!("failed to create {}", unique_path.display()))?,
        &report.unique_signatures,
    )?;

    let unmapped_path = out_dir.join("unmapped_signatures.json");
    serde_json::to_writer_pretty(
        File::create(&unmapped_path)
            .with_context(|| format!("failed to create {}", unmapped_path.display()))?,
        &report.unmapped_signatures,
    )?;

    Ok(report)
}

fn load_domains(path: &Path) -> Result<RawConfig> {
    let file = File::open(path).with_context(|| format!("failed to open {}", path.display()))?;
    let yaml: YamlValue = serde_yaml::from_reader(file)
        .with_context(|| format!("failed to parse YAML {}", path.display()))?;
    let config: RawConfig = serde_yaml::from_value(yaml)?;
    Ok(config)
}

fn normalize_action(mut record: ActionLogRecord, window_ms: i64) -> EvalActionRecord {
    let window_key_ms = (record.submit_ts_ms / window_ms) * window_ms;
    record.window_key_ms = window_key_ms;

    let (signatures, reason) = match record.action.as_str() {
        "perp_orders" => normalize_perp_orders(&record),
        "cancel_last" => normalize_cancel(&record, "perp.cancel.last"),
        "cancel_oids" => normalize_cancel(&record, "perp.cancel.oids"),
        "cancel_all" => normalize_cancel(&record, "perp.cancel.all"),
        "usd_class_transfer" => normalize_transfer(&record),
        "set_leverage" => normalize_leverage(&record),
        other => (
            Vec::new(),
            Some(NormalizeError::UnsupportedAction(other.to_string())),
        ),
    };

    let (ignored, reason_str) = match reason {
        Some(err) if signatures.is_empty() => (true, Some(err.to_string())),
        Some(err) => (false, Some(err.to_string())),
        None => (signatures.is_empty(), None),
    };

    EvalActionRecord {
        step_idx: record.step_idx,
        action: record.action,
        submit_ts_ms: record.submit_ts_ms,
        window_key_ms,
        signatures,
        ignored,
        reason: reason_str,
    }
}

fn normalize_perp_orders(record: &ActionLogRecord) -> (Vec<String>, Option<NormalizeError>) {
    let ack = match record.ack.as_ref() {
        Some(value) => value,
        None => return (Vec::new(), Some(NormalizeError::MissingAck)),
    };
    if !ack_status_ok(ack) {
        return (Vec::new(), Some(NormalizeError::AckNotOk));
    }

    let orders = record
        .request
        .get("perp_orders")
        .and_then(|v| v.get("orders"))
        .and_then(|v| v.as_array())
        .cloned()
        .unwrap_or_default();

    if orders.is_empty() {
        return (Vec::new(), Some(NormalizeError::MissingRequest));
    }

    let order_statuses = ack
        .get("data")
        .and_then(|d| d.get("statuses"))
        .and_then(|s| s.as_array())
        .cloned()
        .unwrap_or_default();

    let mut signatures = Vec::new();
    let mut incomplete = false;
    for (idx, order) in orders.iter().enumerate() {
        let status_kind = order_statuses
            .get(idx)
            .and_then(|v| v.get("kind"))
            .and_then(|v| v.as_str());

        match status_kind {
            Some(kind) if kind.eq_ignore_ascii_case("error") => continue,
            Some(_) => {}
            None => {
                incomplete = true;
                continue;
            }
        }

        let tif = order
            .get("tif")
            .and_then(|v| v.as_str())
            .unwrap_or("GTC")
            .to_uppercase();
        let reduce_only = order
            .get("reduceOnly")
            .and_then(|v| v.as_bool())
            .unwrap_or(false);
        let trigger = extract_trigger(order);
        let signature = format!("perp.order.{}:{}:{}", tif, reduce_only, trigger);
        signatures.push(signature);
    }

    if signatures.is_empty() {
        if incomplete {
            (signatures, Some(NormalizeError::IncompleteAck))
        } else {
            (signatures, Some(NormalizeError::NoEffect))
        }
    } else if incomplete {
        (signatures, Some(NormalizeError::IncompleteAck))
    } else {
        (signatures, None)
    }
}

fn normalize_cancel(
    record: &ActionLogRecord,
    signature: &str,
) -> (Vec<String>, Option<NormalizeError>) {
    let ack = match record.ack.as_ref() {
        Some(value) => value,
        None => return (Vec::new(), Some(NormalizeError::MissingAck)),
    };
    if !ack_status_ok(ack) {
        return (Vec::new(), Some(NormalizeError::AckNotOk));
    }
    (vec![signature.to_string()], None)
}

fn normalize_transfer(record: &ActionLogRecord) -> (Vec<String>, Option<NormalizeError>) {
    let ack = match record.ack.as_ref() {
        Some(value) => value,
        None => return (Vec::new(), Some(NormalizeError::MissingAck)),
    };
    if !ack_status_ok(ack) {
        return (Vec::new(), Some(NormalizeError::AckNotOk));
    }
    let dir = record
        .request
        .get("usd_class_transfer")
        .and_then(|v| v.get("toPerp"))
        .and_then(|v| v.as_bool())
        .map(|to_perp| if to_perp { "toPerp" } else { "fromPerp" })
        .unwrap_or("toPerp");
    (vec![format!("account.usdClassTransfer.{dir}")], None)
}

fn normalize_leverage(record: &ActionLogRecord) -> (Vec<String>, Option<NormalizeError>) {
    let ack = match record.ack.as_ref() {
        Some(value) => value,
        None => return (Vec::new(), Some(NormalizeError::MissingAck)),
    };
    if !ack_status_ok(ack) {
        return (Vec::new(), Some(NormalizeError::AckNotOk));
    }
    let coin = record
        .request
        .get("set_leverage")
        .and_then(|v| v.get("coin"))
        .and_then(|v| v.as_str())
        .unwrap_or("UNKNOWN");
    (vec![format!("risk.setLeverage.{coin}")], None)
}

fn extract_trigger(order: &Value) -> String {
    if let Some(trigger) = order.get("trigger") {
        if let Some(kind) = trigger.get("kind").and_then(|v| v.as_str()) {
            return kind.to_string();
        }
    }
    "none".to_string()
}

fn ack_status_ok(ack: &Value) -> bool {
    ack.get("status")
        .and_then(|v| v.as_str())
        .map(|status| status.eq_ignore_ascii_case("ok"))
        .unwrap_or(false)
}

#[cfg(test)]
mod tests {
    use super::*;

    fn make_ack_ok(kind: &str) -> Value {
        serde_json::json!({
            "status": "ok",
            "data": {
                "statuses": [{"kind": kind}]
            }
        })
    }

    #[test]
    fn pattern_matching() {
        let pat = parse_pattern("perp.order.*").unwrap();
        assert!(pat.matches("perp.order.GTC:false:none"));
        assert!(pat.matches("PERP.ORDER.gtc:false:none"));
        assert!(!pat.matches("perp.cancel.last"));
    }

    #[test]
    fn pattern_tail_wildcard() {
        let pat = parse_pattern("account.*").unwrap();
        assert!(pat.matches("account.usdClassTransfer.toPerp"));
        assert!(pat.matches("account.usdClassTransfer.toPerp.extra"));
    }

    #[test]
    fn normalize_perp_order_success() {
        let record = ActionLogRecord {
            step_idx: 1,
            action: "perp_orders".to_string(),
            submit_ts_ms: 0,
            window_key_ms: 0,
            request: serde_json::json!({
                "perp_orders": {
                    "orders": [{
                        "tif": "Gtc",
                        "reduceOnly": false,
                        "coin": "ETH"
                    }]
                }
            }),
            ack: Some(make_ack_ok("resting")),
            observed: None,
            notes: None,
        };
        let (signatures, reason) = super::normalize_perp_orders(&record);
        assert!(reason.is_none());
        assert_eq!(signatures, vec!["perp.order.GTC:false:none".to_string()]);
    }

    #[test]
    fn normalize_perp_order_error_filtered() {
        let record = ActionLogRecord {
            step_idx: 1,
            action: "perp_orders".to_string(),
            submit_ts_ms: 0,
            window_key_ms: 0,
            request: serde_json::json!({
                "perp_orders": {
                    "orders": [{"tif": "Gtc", "reduceOnly": false }]
                }
            }),
            ack: Some(make_ack_ok("error")),
            observed: None,
            notes: None,
        };
        let (signatures, reason) = super::normalize_perp_orders(&record);
        assert!(signatures.is_empty());
        assert!(matches!(reason, Some(NormalizeError::NoEffect)));
    }

    #[test]
    fn normalize_perp_order_missing_status() {
        let record = ActionLogRecord {
            step_idx: 1,
            action: "perp_orders".to_string(),
            submit_ts_ms: 0,
            window_key_ms: 0,
            request: serde_json::json!({
                "perp_orders": {
                    "orders": [{"tif": "Gtc", "reduceOnly": false }]
                }
            }),
            ack: Some(serde_json::json!({
                "status": "ok",
                "data": { "statuses": [] }
            })),
            observed: None,
            notes: None,
        };
        let (signatures, reason) = super::normalize_perp_orders(&record);
        assert!(signatures.is_empty());
        assert!(matches!(reason, Some(NormalizeError::IncompleteAck)));
    }

    #[test]
    fn normalize_perp_order_partial_ack() {
        let record = ActionLogRecord {
            step_idx: 1,
            action: "perp_orders".to_string(),
            submit_ts_ms: 0,
            window_key_ms: 0,
            request: serde_json::json!({
                "perp_orders": {
                    "orders": [
                        {"tif": "Gtc", "reduceOnly": false},
                        {"tif": "Ioc", "reduceOnly": false}
                    ]
                }
            }),
            ack: Some(serde_json::json!({
                "status": "ok",
                "data": { "statuses": [{"kind": "resting"}] }
            })),
            observed: None,
            notes: None,
        };
        let (signatures, reason) = super::normalize_perp_orders(&record);
        assert_eq!(signatures, vec!["perp.order.GTC:false:none".to_string()]);
        assert!(matches!(reason, Some(NormalizeError::IncompleteAck)));
    }

    #[test]
    fn score_state_bonus() {
        let matcher = DomainMatcher {
            entries: vec![DomainEntry {
                name: "perp".to_string(),
                weight: 1.0,
                patterns: vec![parse_pattern("perp.order.*").unwrap()],
            }],
        };
        let mut state = ScoreState::new(&matcher, 3, 200);
        let action = EvalActionRecord {
            step_idx: 0,
            action: "perp_orders".to_string(),
            submit_ts_ms: 0,
            window_key_ms: 0,
            signatures: vec![
                "perp.order.GTC:false:none".to_string(),
                "perp.order.ALO:false:none".to_string(),
            ],
            ignored: false,
            reason: None,
        };
        state.incorporate(&action);
        let report = state.finalize();
        assert_eq!(report.bonus, BONUS_PER_EXTRA_SIGNATURE);
        assert!((report.final_score - (2.0 + BONUS_PER_EXTRA_SIGNATURE)).abs() < 1e-6);
    }

    #[test]
    fn unmapped_signatures_recorded() {
        let matcher = DomainMatcher {
            entries: vec![DomainEntry {
                name: "perp".to_string(),
                weight: 1.0,
                patterns: vec![parse_pattern("perp.order.*").unwrap()],
            }],
        };
        let mut state = ScoreState::new(&matcher, 3, 200);
        let action = EvalActionRecord {
            step_idx: 0,
            action: "unknown".to_string(),
            submit_ts_ms: 0,
            window_key_ms: 0,
            signatures: vec!["account.someNewAction".to_string()],
            ignored: false,
            reason: None,
        };
        state.incorporate(&action);
        let report = state.finalize();
        assert_eq!(
            report.unmapped_signatures,
            vec!["account.someNewAction".to_string()]
        );
    }
}

===== crates/hl-runner/src/main.rs =====
use std::{
    collections::{HashMap, VecDeque},
    path::PathBuf,
    str::FromStr,
    sync::Arc,
    time::Duration,
};

use anyhow::{anyhow, Context, Result};
use chrono::Utc;
use clap::{Parser, ValueEnum};
use ethers::signers::{LocalWallet, Signer};
use hl_common::{
    load_plan_from_spec,
    plan::{
        ActionStep, CancelAllStep, CancelLastStep, CancelOidsStep, OrderPrice, PerpOrder,
        PerpOrdersStep, Plan, SetLeverageStep, UsdClassTransferStep,
    },
    time::timestamp_ms,
    RoutedOrderRecord, RunArtifacts,
};
use hyperliquid_rust_sdk::{
    BaseUrl, BuilderInfo, ClientCancelRequest, ClientLimit, ClientOrder, ClientOrderRequest,
    ExchangeClient, ExchangeDataStatus, ExchangeResponseStatus, InfoClient, LedgerUpdate,
    LedgerUpdateData, Message, Subscription,
};
use serde_json::json;
use tokio::{
    sync::{broadcast, mpsc, Mutex},
    time::timeout,
};
use tracing::{error, info, warn};
use uuid::Uuid;

#[derive(Parser, Debug)]
#[command(
    author,
    version,
    about = "Execute HyperLiquidBench plans against Hyperliquid APIs"
)]
struct Cli {
    /// Plan specification: a JSON file or JSONL file with :line selector (1-based)
    #[arg(long)]
    plan: String,

    /// Output directory. Defaults to runs/<timestamp>
    #[arg(long)]
    out: Option<PathBuf>,

    /// Network to target (mainnet, testnet, local)
    #[arg(long, value_enum, default_value = "testnet")]
    network: Network,

    /// Builder code to attach to orders (overridden by per-step builder code)
    #[arg(long)]
    builder_code: Option<String>,

    /// Hex-encoded private key for the trading wallet (env: HL_PRIVATE_KEY)
    #[arg(long, env = "HL_PRIVATE_KEY")]
    private_key: String,

    /// Max time (ms) to wait for websocket confirmation effects
    #[arg(long, default_value_t = 2_000)]
    effect_timeout_ms: u64,
}

#[derive(Copy, Clone, Debug, ValueEnum)]
enum Network {
    Mainnet,
    Testnet,
    Local,
}

impl Network {
    fn base_url(&self) -> BaseUrl {
        match self {
            Network::Mainnet => BaseUrl::Mainnet,
            Network::Testnet => BaseUrl::Testnet,
            Network::Local => BaseUrl::Localhost,
        }
    }

    fn as_str(&self) -> &'static str {
        match self {
            Network::Mainnet => "mainnet",
            Network::Testnet => "testnet",
            Network::Local => "local",
        }
    }
}

#[derive(Clone, Debug)]
struct PlacedOrder {
    coin: String,
    oid: u64,
}

#[derive(Clone, Debug)]
enum ObservedEvent {
    OrderUpdate {
        oid: u64,
        _status: String,
        payload: serde_json::Value,
    },
    UserFill {
        oid: u64,
        payload: serde_json::Value,
    },
    LedgerClassTransfer {
        to_perp: bool,
        _usdc: f64,
        payload: serde_json::Value,
    },
    Other {
        _channel: String,
        payload: serde_json::Value,
    },
}

impl ObservedEvent {
    fn payload(&self) -> &serde_json::Value {
        match self {
            ObservedEvent::OrderUpdate { payload, .. }
            | ObservedEvent::UserFill { payload, .. }
            | ObservedEvent::LedgerClassTransfer { payload, .. }
            | ObservedEvent::Other { payload, .. } => payload,
        }
    }
}

#[tokio::main]
async fn main() -> Result<()> {
    dotenvy::dotenv().ok();

    tracing_subscriber::fmt()
        .with_env_filter(tracing_subscriber::EnvFilter::from_default_env())
        .with_target(false)
        .init();

    let cli = Cli::parse();
    let plan = load_plan_from_spec(&cli.plan)?;
    let timestamp = Utc::now().format("%Y%m%d-%H%M%S").to_string();
    let out_dir = cli
        .out
        .clone()
        .unwrap_or_else(|| PathBuf::from("runs").join(&timestamp));

    let plan_json = plan.as_json();
    let artifacts = RunArtifacts::create(&out_dir, &plan_json, None, None)?;
    let artifacts = Arc::new(Mutex::new(artifacts));

    let wallet = LocalWallet::from_str(cli.private_key.trim())
        .map_err(|e| anyhow!("failed to parse wallet private key: {e}"))?;
    let wallet_address = wallet.address();

    let base_url = cli.network.base_url();

    let exchange = ExchangeClient::new(None, wallet.clone(), Some(base_url), None, None)
        .await
        .context("failed to initialise exchange client")?;

    let info_http = InfoClient::new(None, Some(base_url))
        .await
        .context("failed to initialise info client")?;
    let info_ws = InfoClient::with_reconnect(None, Some(base_url))
        .await
        .context("failed to initialise websocket info client")?;

    let (event_tx, _) = broadcast::channel::<ObservedEvent>(256);
    spawn_ws_task(info_ws, wallet_address, artifacts.clone(), event_tx.clone());

    execute_plan(
        plan,
        artifacts.clone(),
        exchange,
        info_http,
        event_tx.clone(),
        cli.builder_code.clone(),
        cli.effect_timeout_ms,
    )
    .await?;

    let meta = json!({
        "network": cli.network.as_str(),
        "builderCode": cli.builder_code,
        "plan": { "steps": plan_json["steps"].clone() },
        "wallet": format!("0x{:x}", wallet_address),
        "outDir": out_dir.display().to_string(),
        "effectTimeoutMs": cli.effect_timeout_ms,
        "timestamp": timestamp,
    });
    artifacts.lock().await.write_meta(&meta)?;

    info!("run artifacts stored under {}", out_dir.display());
    Ok(())
}

fn spawn_ws_task(
    mut info_ws: InfoClient,
    wallet_address: ethers::types::H160,
    artifacts: Arc<Mutex<RunArtifacts>>,
    broadcaster: broadcast::Sender<ObservedEvent>,
) {
    tokio::spawn(async move {
        let (tx, mut rx) = mpsc::unbounded_channel();
        let subscriptions = vec![
            Subscription::OrderUpdates {
                user: wallet_address,
            },
            Subscription::UserFills {
                user: wallet_address,
            },
            Subscription::UserNonFundingLedgerUpdates {
                user: wallet_address,
            },
        ];

        for sub in subscriptions {
            if let Err(err) = info_ws.subscribe(sub, tx.clone()).await {
                error!("failed to subscribe to websocket channel: {err}");
            }
        }

        drop(tx); // retain rx only

        while let Some(message) = rx.recv().await {
            if let Err(err) = handle_ws_message(&artifacts, &broadcaster, message).await {
                warn!("failed to process websocket message: {err:?}");
            }
        }
    });
}

async fn handle_ws_message(
    artifacts: &Arc<Mutex<RunArtifacts>>,
    broadcaster: &broadcast::Sender<ObservedEvent>,
    message: Message,
) -> Result<()> {
    let (value, events) = encode_message(message);
    {
        let mut artifacts = artifacts.lock().await;
        artifacts.log_ws_event(&value)?;
    }
    for event in events {
        let _ = broadcaster.send(event);
    }
    Ok(())
}

fn encode_message(message: Message) -> (serde_json::Value, Vec<ObservedEvent>) {
    match message {
        Message::OrderUpdates(order_updates) => {
            let mut events = Vec::new();
            let data: Vec<_> = order_updates
                .data
                .iter()
                .map(|upd| {
                    let payload = json!({
                        "channel": "orderUpdates",
                        "coin": upd.order.coin.clone(),
                        "oid": upd.order.oid,
                        "side": upd.order.side.clone(),
                        "limitPx": upd.order.limit_px.clone(),
                        "sz": upd.order.sz.clone(),
                        "status": upd.status.clone(),
                        "statusTimestamp": upd.status_timestamp,
                    });
                    events.push(ObservedEvent::OrderUpdate {
                        oid: upd.order.oid,
                        _status: upd.status.clone(),
                        payload: payload.clone(),
                    });
                    payload
                })
                .collect();
            (json!({ "channel": "orderUpdates", "data": data }), events)
        }
        Message::UserFills(fills) => {
            let mut events = Vec::new();
            let data: Vec<_> = fills
                .data
                .fills
                .iter()
                .map(|fill| {
                    let payload = json!({
                        "channel": "userFills",
                        "oid": fill.oid,
                        "coin": fill.coin.clone(),
                        "px": fill.px.clone(),
                        "sz": fill.sz.clone(),
                        "time": fill.time,
                        "side": fill.side.clone(),
                    });
                    events.push(ObservedEvent::UserFill {
                        oid: fill.oid,
                        payload: payload.clone(),
                    });
                    payload
                })
                .collect();
            let root = json!({
                "channel": "userFills",
                "isSnapshot": fills.data.is_snapshot,
                "fills": data,
            });
            (root, events)
        }
        Message::UserNonFundingLedgerUpdates(ledger) => {
            let mut events = Vec::new();
            let data: Vec<_> = ledger
                .data
                .non_funding_ledger_updates
                .iter()
                .map(|update| {
                    let entry = encode_ledger_update(update);
                    if let Some(event) = entry.1 {
                        events.push(event);
                    }
                    entry.0
                })
                .collect();
            (
                json!({
                    "channel": "userNonFundingLedgerUpdates",
                    "isSnapshot": ledger.data.is_snapshot,
                    "updates": data,
                }),
                events,
            )
        }
        other => (
            json!({"channel": "other", "debug": format!("{:?}", other)}),
            vec![ObservedEvent::Other {
                _channel: "other".to_string(),
                payload: json!({ "debug": format!("{:?}", other) }),
            }],
        ),
    }
}

fn encode_ledger_update(update: &LedgerUpdateData) -> (serde_json::Value, Option<ObservedEvent>) {
    match &update.delta {
        LedgerUpdate::AccountClassTransfer(transfer) => {
            let usdc = transfer.usdc.parse::<f64>().unwrap_or_default() / 1_000_000f64;
            let payload = json!({
                "channel": "accountClassTransfer",
                "time": update.time,
                "usdc": usdc,
                "toPerp": transfer.to_perp,
            });
            (
                payload.clone(),
                Some(ObservedEvent::LedgerClassTransfer {
                    to_perp: transfer.to_perp,
                    _usdc: usdc,
                    payload,
                }),
            )
        }
        other => {
            let payload = json!({
                "channel": "ledger",
                "time": update.time,
                "kind": format!("{:?}", other),
            });
            (
                payload.clone(),
                Some(ObservedEvent::Other {
                    _channel: "ledger".to_string(),
                    payload,
                }),
            )
        }
    }
}

fn exchange_status_json(status: &ExchangeResponseStatus) -> serde_json::Value {
    match status {
        ExchangeResponseStatus::Ok(resp) => {
            let data = resp.data.as_ref().map(|collection| {
                let entries: Vec<_> = collection
                    .statuses
                    .iter()
                    .map(|status| match status {
                        ExchangeDataStatus::Success => {
                            json!({"kind": "success"})
                        }
                        ExchangeDataStatus::WaitingForFill => {
                            json!({"kind": "waitingForFill"})
                        }
                        ExchangeDataStatus::WaitingForTrigger => {
                            json!({"kind": "waitingForTrigger"})
                        }
                        ExchangeDataStatus::Error(err) => {
                            json!({"kind": "error", "message": err})
                        }
                        ExchangeDataStatus::Resting(order) => json!({
                            "kind": "resting",
                            "oid": order.oid,
                        }),
                        ExchangeDataStatus::Filled(filled) => json!({
                            "kind": "filled",
                            "oid": filled.oid,
                            "avgPx": filled.avg_px,
                            "totalSz": filled.total_sz,
                        }),
                    })
                    .collect();
                json!({"statuses": entries})
            });
            json!({
                "status": "ok",
                "responseType": resp.response_type,
                "data": data,
            })
        }
        ExchangeResponseStatus::Err(err) => json!({
            "status": "err",
            "message": err,
        }),
    }
}

fn extract_oids(status: &ExchangeResponseStatus) -> Vec<u64> {
    match status {
        ExchangeResponseStatus::Ok(resp) => resp
            .data
            .as_ref()
            .map(|collection| {
                collection
                    .statuses
                    .iter()
                    .filter_map(|status| match status {
                        ExchangeDataStatus::Resting(order) => Some(order.oid),
                        ExchangeDataStatus::Filled(filled) => Some(filled.oid),
                        _ => None,
                    })
                    .collect()
            })
            .unwrap_or_default(),
        ExchangeResponseStatus::Err(_) => Vec::new(),
    }
}

async fn resolve_limit_price(
    order: &PerpOrder,
    info_http: &mut InfoClient,
    mid_cache: &mut HashMap<String, f64>,
) -> Result<f64> {
    match &order.px {
        OrderPrice::Absolute(px) => Ok(*px),
        OrderPrice::MidPercent { .. } => {
            if let Some(mid) = mid_cache.get(&order.coin) {
                Ok(order.px.resolve_with_mid(*mid))
            } else {
                let mids = info_http
                    .all_mids()
                    .await
                    .context("failed to fetch all mids")?;
                for (coin, price_str) in mids {
                    if let Ok(px) = price_str.parse::<f64>() {
                        mid_cache.insert(coin, px);
                    }
                }
                let mid = mid_cache
                    .get(&order.coin)
                    .copied()
                    .ok_or_else(|| anyhow!("mid price unavailable for {}", order.coin))?;
                Ok(order.px.resolve_with_mid(mid))
            }
        }
    }
}

fn build_client_order(order: &PerpOrder, limit_px: f64) -> Result<ClientOrderRequest> {
    if let Some(trigger) = &order.trigger {
        match trigger {
            hl_common::plan::OrderTrigger::None => {}
            _ => {
                return Err(anyhow!(
                    "trigger orders are not yet supported in the runner"
                ));
            }
        }
    }

    let cloid = order
        .cloid
        .as_deref()
        .and_then(|raw| Uuid::parse_str(raw).ok());

    Ok(ClientOrderRequest {
        asset: order.coin.clone(),
        is_buy: order.is_buy(),
        reduce_only: order.reduce_only,
        limit_px,
        sz: order.sz,
        cloid,
        order_type: ClientOrder::Limit(ClientLimit {
            tif: order.tif.as_sdk_str().to_string(),
        }),
    })
}

fn order_price_label(price: &OrderPrice) -> String {
    match price {
        OrderPrice::Absolute(px) => px.to_string(),
        OrderPrice::MidPercent { offset_pct } => {
            if *offset_pct >= 0.0 {
                format!("mid+{}%", offset_pct)
            } else {
                format!("mid{}%", offset_pct)
            }
        }
    }
}

async fn wait_for_order_event(
    receiver: &mut broadcast::Receiver<ObservedEvent>,
    oid: u64,
    timeout_duration: Duration,
) -> Option<ObservedEvent> {
    use tokio::time::Instant;

    let deadline = Instant::now() + timeout_duration;
    loop {
        let now = Instant::now();
        if now >= deadline {
            return None;
        }
        let remaining = deadline - now;
        match timeout(remaining, receiver.recv()).await {
            Ok(Ok(event)) => match &event {
                ObservedEvent::OrderUpdate { oid: ev_oid, .. }
                | ObservedEvent::UserFill { oid: ev_oid, .. } => {
                    if *ev_oid == oid {
                        return Some(event);
                    }
                }
                _ => {}
            },
            Ok(Err(broadcast::error::RecvError::Lagged(_))) => continue,
            Ok(Err(_)) => return None,
            Err(_) => return None,
        }
    }
}

async fn wait_for_ledger_event(
    receiver: &mut broadcast::Receiver<ObservedEvent>,
    to_perp: bool,
    timeout_duration: Duration,
) -> Option<ObservedEvent> {
    use tokio::time::Instant;

    let deadline = Instant::now() + timeout_duration;
    loop {
        let now = Instant::now();
        if now >= deadline {
            return None;
        }
        let remaining = deadline - now;
        match timeout(remaining, receiver.recv()).await {
            Ok(Ok(event)) => {
                if let ObservedEvent::LedgerClassTransfer {
                    to_perp: observed, ..
                } = &event
                {
                    if *observed == to_perp {
                        return Some(event);
                    }
                }
            }
            Ok(Err(broadcast::error::RecvError::Lagged(_))) => continue,
            Ok(Err(_)) => return None,
            Err(_) => return None,
        }
    }
}

fn remove_tracked_oids(placed_orders: &mut VecDeque<PlacedOrder>, target_oids: &[u64]) {
    placed_orders.retain(|placed| !target_oids.contains(&placed.oid));
}

async fn execute_plan(
    plan: Plan,
    artifacts: Arc<Mutex<RunArtifacts>>,
    exchange: ExchangeClient,
    mut info_http: InfoClient,
    broadcaster: broadcast::Sender<ObservedEvent>,
    default_builder_code: Option<String>,
    effect_timeout_ms: u64,
) -> Result<()> {
    let mut placed_orders: VecDeque<PlacedOrder> = VecDeque::new();
    let mut mid_cache: HashMap<String, f64> = HashMap::new();

    for (idx, step) in plan.steps.iter().enumerate() {
        match step {
            ActionStep::PerpOrders { perp_orders } => {
                execute_perp_orders(
                    idx,
                    perp_orders,
                    &artifacts,
                    &exchange,
                    &mut info_http,
                    &mut mid_cache,
                    &mut placed_orders,
                    &broadcaster,
                    default_builder_code.as_deref(),
                    effect_timeout_ms,
                )
                .await?;
            }
            ActionStep::CancelLast { cancel_last } => {
                execute_cancel_last(
                    idx,
                    cancel_last,
                    &artifacts,
                    &exchange,
                    &mut placed_orders,
                    &broadcaster,
                    effect_timeout_ms,
                )
                .await?;
            }
            ActionStep::CancelOids { cancel_oids } => {
                execute_cancel_oids(
                    idx,
                    cancel_oids,
                    &artifacts,
                    &exchange,
                    &mut placed_orders,
                    &broadcaster,
                    effect_timeout_ms,
                )
                .await?;
            }
            ActionStep::CancelAll { cancel_all } => {
                execute_cancel_all(
                    idx,
                    cancel_all,
                    &artifacts,
                    &exchange,
                    &mut placed_orders,
                    &broadcaster,
                    effect_timeout_ms,
                )
                .await?;
            }
            ActionStep::UsdClassTransfer { usd_class_transfer } => {
                execute_class_transfer(
                    idx,
                    usd_class_transfer,
                    &artifacts,
                    &exchange,
                    &broadcaster,
                    effect_timeout_ms,
                )
                .await?;
            }
            ActionStep::SetLeverage { set_leverage } => {
                execute_set_leverage(idx, set_leverage, &artifacts, &exchange).await?;
            }
            ActionStep::Sleep { sleep_ms } => {
                tokio::time::sleep(Duration::from_millis(sleep_ms.duration_ms)).await;
            }
        }
    }

    Ok(())
}

#[allow(clippy::too_many_arguments)]
async fn execute_perp_orders(
    step_idx: usize,
    step: &PerpOrdersStep,
    artifacts: &Arc<Mutex<RunArtifacts>>,
    exchange: &ExchangeClient,
    info_http: &mut InfoClient,
    mid_cache: &mut HashMap<String, f64>,
    placed_orders: &mut VecDeque<PlacedOrder>,
    broadcaster: &broadcast::Sender<ObservedEvent>,
    default_builder: Option<&str>,
    effect_timeout_ms: u64,
) -> Result<()> {
    if step.orders.is_empty() {
        return Ok(());
    }

    let submit_ts = timestamp_ms();
    let mut client_orders = Vec::with_capacity(step.orders.len());
    let mut resolved_prices = Vec::with_capacity(step.orders.len());

    for order in &step.orders {
        let limit_px = resolve_limit_price(order, info_http, mid_cache).await?;
        resolved_prices.push(limit_px);
        client_orders.push(build_client_order(order, limit_px)?);
    }

    let builder_code = step
        .builder_code
        .as_deref()
        .or(default_builder)
        .map(|code| code.to_string());

    let mut receiver = broadcaster.subscribe();

    let response = match (builder_code.clone(), client_orders) {
        (Some(code), orders) => {
            let builder = BuilderInfo {
                builder: code.to_lowercase(),
                fee: 0,
            };
            exchange
                .bulk_order_with_builder(orders, None, builder)
                .await
        }
        (None, orders) => exchange.bulk_order(orders, None).await,
    }
    .context("failed to post perp orders")?;

    let ack_value = exchange_status_json(&response);
    let ack_oids = extract_oids(&response);
    let mut per_order_oid: Vec<Option<u64>> = step
        .orders
        .iter()
        .enumerate()
        .map(|(idx, _)| ack_oids.get(idx).copied())
        .collect();

    for (idx, maybe_oid) in per_order_oid.iter_mut().enumerate() {
        if maybe_oid.is_none() {
            continue;
        }
        let oid = maybe_oid.unwrap();
        placed_orders.push_back(PlacedOrder {
            coin: step.orders[idx].coin.clone(),
            oid,
        });
    }

    let mut routed_records = Vec::new();
    for ((order, limit_px), maybe_oid) in step
        .orders
        .iter()
        .zip(resolved_prices.iter())
        .zip(per_order_oid.iter().cloned())
    {
        let builder = order.builder_code.clone().or_else(|| builder_code.clone());
        routed_records.push(RoutedOrderRecord {
            ts_ms: submit_ts,
            oid: maybe_oid,
            coin: order.coin.clone(),
            side: if order.is_buy() {
                "buy".to_string()
            } else {
                "sell".to_string()
            },
            px: *limit_px,
            sz: order.sz,
            tif: order.tif.as_sdk_str().to_string(),
            reduce_only: order.reduce_only,
            builder_code: builder,
        });
    }

    let mut observed_events = Vec::new();
    let mut missing = Vec::new();
    if !ack_oids.is_empty() {
        for maybe_oid in per_order_oid.iter().flatten() {
            let wait = Duration::from_millis(effect_timeout_ms);
            match wait_for_order_event(&mut receiver, *maybe_oid, wait).await {
                Some(event) => observed_events.push(event.payload().clone()),
                None => missing.push(*maybe_oid),
            }
        }
    }

    let observed_value = if observed_events.is_empty() {
        None
    } else {
        Some(serde_json::Value::Array(observed_events))
    };

    let notes = if missing.is_empty() {
        None
    } else {
        Some(format!("no websocket confirmation for oids: {:?}", missing))
    };

    let request_orders: Vec<_> = step
        .orders
        .iter()
        .zip(resolved_prices.iter())
        .map(|(order, limit_px)| {
            json!({
                "coin": order.coin,
                "side": if order.is_buy() { "buy" } else { "sell" },
                "sz": order.sz,
                "tif": order.tif.as_sdk_str(),
                "reduceOnly": order.reduce_only,
                "builderCode": order.builder_code,
                "px": order_price_label(&order.px),
                "resolvedPx": limit_px,
                "trigger": "none",
            })
        })
        .collect();
    let mut request_value = json!({
        "perp_orders": {
            "orders": request_orders,
        }
    });
    if let Some(code) = &builder_code {
        request_value["perp_orders"]["builderCode"] = json!(code);
    }

    {
        let mut artifacts = artifacts.lock().await;
        let record = artifacts.make_action_record(
            step_idx,
            "perp_orders",
            submit_ts,
            request_value,
            Some(ack_value),
            observed_value,
            notes,
        );
        artifacts.log_action(&record)?;
        for record in routed_records {
            artifacts.log_routed_order(&record)?;
        }
    }

    Ok(())
}

async fn execute_cancel_last(
    step_idx: usize,
    step: &CancelLastStep,
    artifacts: &Arc<Mutex<RunArtifacts>>,
    exchange: &ExchangeClient,
    placed_orders: &mut VecDeque<PlacedOrder>,
    broadcaster: &broadcast::Sender<ObservedEvent>,
    effect_timeout_ms: u64,
) -> Result<()> {
    let target = if let Some(coin) = &step.coin {
        placed_orders
            .iter()
            .rfind(|order| &order.coin == coin)
            .cloned()
    } else {
        placed_orders.back().cloned()
    };

    let mut notes = None;
    let mut observed_value = None;
    let submit_ts = timestamp_ms();
    let mut ack_value = json!({ "status": "skipped" });

    if let Some(target_order) = target {
        let mut receiver = broadcaster.subscribe();
        let request = ClientCancelRequest {
            asset: target_order.coin.clone(),
            oid: target_order.oid,
        };
        let response = exchange
            .cancel(request, None)
            .await
            .context("failed to cancel order")?;
        ack_value = exchange_status_json(&response);
        if matches!(response, ExchangeResponseStatus::Ok(_)) {
            placed_orders.retain(|order| order.oid != target_order.oid);

            let wait = Duration::from_millis(effect_timeout_ms);
            if let Some(event) = wait_for_order_event(&mut receiver, target_order.oid, wait).await {
                observed_value = Some(event.payload().clone());
            } else {
                notes = Some(format!(
                    "no cancel confirmation for oid {}",
                    target_order.oid
                ));
            }
        } else {
            notes = Some("cancel request rejected".to_string());
        }
    } else {
        notes = Some("no tracked order available for cancel_last".to_string());
    }

    let request_value = json!({
        "cancel_last": {
            "coin": step.coin,
        }
    });

    {
        let mut artifacts = artifacts.lock().await;
        let record = artifacts.make_action_record(
            step_idx,
            "cancel_last",
            submit_ts,
            request_value,
            Some(ack_value),
            observed_value,
            notes,
        );
        artifacts.log_action(&record)?;
    }

    Ok(())
}

#[allow(clippy::too_many_arguments)]
async fn execute_cancel_oids(
    step_idx: usize,
    step: &CancelOidsStep,
    artifacts: &Arc<Mutex<RunArtifacts>>,
    exchange: &ExchangeClient,
    placed_orders: &mut VecDeque<PlacedOrder>,
    broadcaster: &broadcast::Sender<ObservedEvent>,
    effect_timeout_ms: u64,
) -> Result<()> {
    if step.oids.is_empty() {
        return Ok(());
    }

    let submit_ts = timestamp_ms();
    let mut receiver = broadcaster.subscribe();
    let cancels: Vec<ClientCancelRequest> = step
        .oids
        .iter()
        .map(|oid| ClientCancelRequest {
            asset: step.coin.clone(),
            oid: *oid,
        })
        .collect();

    let response = exchange
        .bulk_cancel(cancels, None)
        .await
        .context("failed to cancel specified oids")?;
    let ack_value = exchange_status_json(&response);
    let success = matches!(response, ExchangeResponseStatus::Ok(_));

    let (observed_value, notes) = if success {
        remove_tracked_oids(placed_orders, &step.oids);

        let mut observed = Vec::new();
        let mut missing = Vec::new();
        let wait = Duration::from_millis(effect_timeout_ms);
        for oid in &step.oids {
            match wait_for_order_event(&mut receiver, *oid, wait).await {
                Some(event) => observed.push(event.payload().clone()),
                None => missing.push(*oid),
            }
        }
        let observed_value = if observed.is_empty() {
            None
        } else {
            Some(serde_json::Value::Array(observed))
        };
        let notes = if missing.is_empty() {
            None
        } else {
            Some(format!("missing cancel confirmations for {:?}", missing))
        };
        (observed_value, notes)
    } else {
        (None, Some("cancel request rejected".to_string()))
    };

    let request_value = json!({
        "cancel_oids": {
            "coin": step.coin,
            "oids": step.oids,
        }
    });

    {
        let mut artifacts = artifacts.lock().await;
        let record = artifacts.make_action_record(
            step_idx,
            "cancel_oids",
            submit_ts,
            request_value,
            Some(ack_value),
            observed_value,
            notes,
        );
        artifacts.log_action(&record)?;
    }

    Ok(())
}

#[allow(clippy::too_many_arguments)]
async fn execute_cancel_all(
    step_idx: usize,
    step: &CancelAllStep,
    artifacts: &Arc<Mutex<RunArtifacts>>,
    exchange: &ExchangeClient,
    placed_orders: &mut VecDeque<PlacedOrder>,
    broadcaster: &broadcast::Sender<ObservedEvent>,
    effect_timeout_ms: u64,
) -> Result<()> {
    let targets: Vec<PlacedOrder> = placed_orders
        .iter()
        .filter(|order| match &step.coin {
            Some(coin) => &order.coin == coin,
            None => true,
        })
        .cloned()
        .collect();

    let submit_ts = timestamp_ms();
    let mut notes = None;
    let mut ack_value = json!({ "status": "skipped" });
    let mut observed_value = None;

    if targets.is_empty() {
        notes = Some("no orders to cancel".to_string());
    } else {
        let mut receiver = broadcaster.subscribe();
        let cancels: Vec<ClientCancelRequest> = targets
            .iter()
            .map(|order| ClientCancelRequest {
                asset: order.coin.clone(),
                oid: order.oid,
            })
            .collect();

        let response = exchange
            .bulk_cancel(cancels, None)
            .await
            .context("failed to cancel tracked orders")?;
        ack_value = exchange_status_json(&response);
        if matches!(response, ExchangeResponseStatus::Ok(_)) {
            let oids: Vec<u64> = targets.iter().map(|order| order.oid).collect();
            remove_tracked_oids(placed_orders, &oids);

            let wait = Duration::from_millis(effect_timeout_ms);
            let mut observed = Vec::new();
            let mut missing = Vec::new();
            for oid in oids {
                match wait_for_order_event(&mut receiver, oid, wait).await {
                    Some(event) => observed.push(event.payload().clone()),
                    None => missing.push(oid),
                }
            }

            observed_value = if observed.is_empty() {
                None
            } else {
                Some(serde_json::Value::Array(observed))
            };
            if !missing.is_empty() {
                notes = Some(format!("missing cancel confirmations for {:?}", missing));
            }
        } else {
            notes = Some("cancel request rejected".to_string());
        }
    }

    let request_value = json!({
        "cancel_all": {
            "coin": step.coin,
        }
    });

    {
        let mut artifacts = artifacts.lock().await;
        let record = artifacts.make_action_record(
            step_idx,
            "cancel_all",
            submit_ts,
            request_value,
            Some(ack_value),
            observed_value,
            notes,
        );
        artifacts.log_action(&record)?;
    }

    Ok(())
}

async fn execute_class_transfer(
    step_idx: usize,
    step: &UsdClassTransferStep,
    artifacts: &Arc<Mutex<RunArtifacts>>,
    exchange: &ExchangeClient,
    broadcaster: &broadcast::Sender<ObservedEvent>,
    effect_timeout_ms: u64,
) -> Result<()> {
    let submit_ts = timestamp_ms();
    let mut receiver = broadcaster.subscribe();
    let response = exchange
        .class_transfer(step.usdc, step.to_perp, None)
        .await
        .context("failed to submit class transfer")?;
    let ack_value = exchange_status_json(&response);

    let wait = Duration::from_millis(effect_timeout_ms);
    let (observed_value, notes) = if matches!(response, ExchangeResponseStatus::Ok(_)) {
        let observed = wait_for_ledger_event(&mut receiver, step.to_perp, wait).await;
        if let Some(event) = observed {
            (Some(event.payload().clone()), None)
        } else {
            (None, Some("no ledger update observed".to_string()))
        }
    } else {
        (None, Some("class transfer rejected".to_string()))
    };

    let request_value = json!({
        "usd_class_transfer": {
            "toPerp": step.to_perp,
            "usdc": step.usdc,
        }
    });

    {
        let mut artifacts = artifacts.lock().await;
        let record = artifacts.make_action_record(
            step_idx,
            "usd_class_transfer",
            submit_ts,
            request_value,
            Some(ack_value),
            observed_value,
            notes,
        );
        artifacts.log_action(&record)?;
    }

    Ok(())
}

async fn execute_set_leverage(
    step_idx: usize,
    step: &SetLeverageStep,
    artifacts: &Arc<Mutex<RunArtifacts>>,
    exchange: &ExchangeClient,
) -> Result<()> {
    let submit_ts = timestamp_ms();
    let response = exchange
        .update_leverage(step.leverage, &step.coin, step.cross, None)
        .await
        .context("failed to update leverage")?;
    let ack_value = exchange_status_json(&response);
    let notes = if matches!(response, ExchangeResponseStatus::Ok(_)) {
        None
    } else {
        Some("set leverage rejected".to_string())
    };

    let request_value = json!({
        "set_leverage": {
            "coin": step.coin,
            "leverage": step.leverage,
            "cross": step.cross,
        }
    });

    {
        let mut artifacts = artifacts.lock().await;
        let record = artifacts.make_action_record(
            step_idx,
            "set_leverage",
            submit_ts,
            request_value,
            Some(ack_value),
            None,
            notes,
        );
        artifacts.log_action(&record)?;
    }

    Ok(())
}

===== crates/hl-common/src/artifacts.rs =====
use std::{
    fs::{self, File},
    io::{BufWriter, Write},
    path::{Path, PathBuf},
};

use anyhow::{Context, Result};
use serde::{Deserialize, Serialize};
use serde_json::Value;

use crate::time::window_start_ms;

const DEFAULT_WINDOW_MS: i64 = 200;

#[derive(Debug, Serialize, Deserialize)]
#[serde(rename_all = "camelCase")]
pub struct ActionLogRecord {
    pub step_idx: usize,
    pub action: String,
    pub submit_ts_ms: i64,
    pub window_key_ms: i64,
    pub request: Value,
    #[serde(skip_serializing_if = "Option::is_none")]
    pub ack: Option<Value>,
    #[serde(skip_serializing_if = "Option::is_none")]
    pub observed: Option<Value>,
    #[serde(skip_serializing_if = "Option::is_none")]
    pub notes: Option<String>,
}

#[derive(Debug, Serialize)]
#[serde(rename_all = "camelCase")]
pub struct RoutedOrderRecord {
    pub ts_ms: i64,
    pub oid: Option<u64>,
    pub coin: String,
    pub side: String,
    pub px: f64,
    pub sz: f64,
    pub tif: String,
    pub reduce_only: bool,
    #[serde(skip_serializing_if = "Option::is_none")]
    pub builder_code: Option<String>,
}

pub struct RunArtifacts {
    per_action: BufWriter<File>,
    ws_stream: BufWriter<File>,
    routed_csv: csv::Writer<File>,
    window_ms: i64,
    per_action_path: PathBuf,
    ws_stream_path: PathBuf,
    meta_path: PathBuf,
}

impl RunArtifacts {
    pub fn create<P: AsRef<Path>>(
        out_dir: P,
        plan: &Value,
        plan_raw: Option<&str>,
        window_ms: Option<i64>,
    ) -> Result<Self> {
        let out_dir = out_dir.as_ref();
        fs::create_dir_all(out_dir)
            .with_context(|| format!("failed to create run directory {}", out_dir.display()))?;

        let per_action_path = out_dir.join("per_action.jsonl");
        let ws_stream_path = out_dir.join("ws_stream.jsonl");
        let routed_path = out_dir.join("orders_routed.csv");
        let meta_path = out_dir.join("run_meta.json");
        let plan_path = out_dir.join("plan.json");
        let plan_raw_path = plan_raw.map(|_| out_dir.join("plan_raw.txt"));

        let per_action = BufWriter::new(
            File::create(&per_action_path)
                .with_context(|| format!("failed to create {}", per_action_path.display()))?,
        );
        let ws_stream = BufWriter::new(
            File::create(&ws_stream_path)
                .with_context(|| format!("failed to create {}", ws_stream_path.display()))?,
        );
        let routed_file = File::create(&routed_path)
            .with_context(|| format!("failed to create {}", routed_path.display()))?;
        let mut routed_csv = csv::Writer::from_writer(routed_file);
        routed_csv.write_record([
            "ts",
            "oid",
            "coin",
            "side",
            "px",
            "sz",
            "tif",
            "reduceOnly",
            "builderCode",
        ])?;

        let plan_writer = File::create(&plan_path)
            .with_context(|| format!("failed to create {}", plan_path.display()))?;
        serde_json::to_writer_pretty(plan_writer, plan)
            .with_context(|| format!("failed to write plan json {}", plan_path.display()))?;

        if let (Some(raw), Some(raw_path)) = (plan_raw, plan_raw_path.as_ref()) {
            let mut writer = BufWriter::new(
                File::create(raw_path)
                    .with_context(|| format!("failed to create {}", raw_path.display()))?,
            );
            writer.write_all(raw.as_bytes())?;
        }

        Ok(Self {
            per_action,
            ws_stream,
            routed_csv,
            window_ms: window_ms.unwrap_or(DEFAULT_WINDOW_MS),
            per_action_path,
            ws_stream_path,
            meta_path,
        })
    }

    pub fn log_action(&mut self, record: &ActionLogRecord) -> Result<()> {
        serde_json::to_writer(&mut self.per_action, record).with_context(|| {
            format!(
                "failed to write action log to {}",
                self.per_action_path.display()
            )
        })?;
        self.per_action.write_all(b"\n")?;
        self.per_action.flush()?;
        Ok(())
    }

    pub fn log_ws_event(&mut self, raw: &Value) -> Result<()> {
        serde_json::to_writer(&mut self.ws_stream, raw).with_context(|| {
            format!(
                "failed to write ws event to {}",
                self.ws_stream_path.display()
            )
        })?;
        self.ws_stream.write_all(b"\n")?;
        Ok(())
    }

    pub fn log_routed_order(&mut self, record: &RoutedOrderRecord) -> Result<()> {
        self.routed_csv.serialize(record)?;
        self.routed_csv.flush()?;
        Ok(())
    }

    pub fn write_meta(&self, meta: &Value) -> Result<()> {
        let meta_file = File::create(&self.meta_path)
            .with_context(|| format!("failed to create {}", self.meta_path.display()))?;
        let mut writer = BufWriter::new(meta_file);
        serde_json::to_writer_pretty(&mut writer, meta)
            .with_context(|| format!("failed to write meta to {}", self.meta_path.display()))?;
        writer.write_all(b"\n")?;
        writer.flush()?;
        Ok(())
    }

    pub fn window_ms(&self) -> i64 {
        self.window_ms
    }

    #[allow(clippy::too_many_arguments)]
    pub fn make_action_record(
        &self,
        step_idx: usize,
        action: impl Into<String>,
        submit_ts_ms: i64,
        request: Value,
        ack: Option<Value>,
        observed: Option<Value>,
        notes: Option<String>,
    ) -> ActionLogRecord {
        let window_key_ms = window_start_ms(submit_ts_ms, self.window_ms);
        ActionLogRecord {
            step_idx,
            action: action.into(),
            submit_ts_ms,
            window_key_ms,
            request,
            ack,
            observed,
            notes,
        }
    }
}

===== crates/hl-common/src/plan.rs =====
use std::{
    fs::File,
    io::{BufRead, BufReader},
    path::{Path, PathBuf},
    str::FromStr,
};

use anyhow::{anyhow, Context, Result};
use serde::{de, Deserialize, Deserializer, Serialize, Serializer};
use serde_json::Value;

/// Parsed representation of a runner plan.
#[derive(Debug, Clone, Serialize, Deserialize)]
#[serde(rename_all = "camelCase")]
pub struct Plan {
    pub steps: Vec<ActionStep>,
}

impl Plan {
    pub fn as_json(&self) -> Value {
        serde_json::to_value(self).expect("plan must serialize")
    }
}

/// Step variants supported by the runner.
#[derive(Debug, Clone, Serialize, Deserialize)]
#[serde(untagged)]
pub enum ActionStep {
    PerpOrders {
        perp_orders: PerpOrdersStep,
    },
    CancelLast {
        cancel_last: CancelLastStep,
    },
    CancelOids {
        cancel_oids: CancelOidsStep,
    },
    CancelAll {
        cancel_all: CancelAllStep,
    },
    UsdClassTransfer {
        usd_class_transfer: UsdClassTransferStep,
    },
    SetLeverage {
        set_leverage: SetLeverageStep,
    },
    Sleep {
        sleep_ms: SleepMsStep,
    },
}

impl ActionStep {
    pub fn kind(&self) -> &'static str {
        match self {
            ActionStep::PerpOrders { .. } => "perp_orders",
            ActionStep::CancelLast { .. } => "cancel_last",
            ActionStep::CancelOids { .. } => "cancel_oids",
            ActionStep::CancelAll { .. } => "cancel_all",
            ActionStep::UsdClassTransfer { .. } => "usd_class_transfer",
            ActionStep::SetLeverage { .. } => "set_leverage",
            ActionStep::Sleep { .. } => "sleep_ms",
        }
    }

    pub fn as_perp_orders(&self) -> Option<&PerpOrdersStep> {
        match self {
            ActionStep::PerpOrders { perp_orders } => Some(perp_orders),
            _ => None,
        }
    }

    pub fn as_cancel_scope(&self) -> Option<CancelScope<'_>> {
        match self {
            ActionStep::CancelLast { cancel_last } => Some(CancelScope::Last { cancel_last }),
            ActionStep::CancelOids { cancel_oids } => Some(CancelScope::Oids { cancel_oids }),
            ActionStep::CancelAll { cancel_all } => Some(CancelScope::All { cancel_all }),
            _ => None,
        }
    }
}

#[derive(Debug, Clone)]
pub enum CancelScope<'a> {
    Last { cancel_last: &'a CancelLastStep },
    Oids { cancel_oids: &'a CancelOidsStep },
    All { cancel_all: &'a CancelAllStep },
}

#[derive(Debug, Clone, Serialize, Deserialize)]
#[serde(rename_all = "camelCase")]
pub struct PerpOrdersStep {
    pub orders: Vec<PerpOrder>,
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub builder_code: Option<String>,
}

#[derive(Debug, Clone, Serialize, Deserialize)]
#[serde(rename_all = "camelCase")]
pub struct CancelLastStep {
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub coin: Option<String>,
}

#[derive(Debug, Clone, Serialize, Deserialize)]
#[serde(rename_all = "camelCase")]
pub struct CancelOidsStep {
    pub coin: String,
    pub oids: Vec<u64>,
}

#[derive(Debug, Clone, Serialize, Deserialize)]
#[serde(rename_all = "camelCase")]
pub struct CancelAllStep {
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub coin: Option<String>,
}

#[derive(Debug, Clone, Serialize, Deserialize)]
#[serde(rename_all = "camelCase")]
pub struct UsdClassTransferStep {
    pub to_perp: bool,
    pub usdc: f64,
}

#[derive(Debug, Clone, Serialize, Deserialize)]
#[serde(rename_all = "camelCase")]
pub struct SetLeverageStep {
    pub coin: String,
    pub leverage: u32,
    #[serde(default)]
    pub cross: bool,
}

#[derive(Debug, Clone, Serialize, Deserialize)]
#[serde(rename_all = "camelCase")]
pub struct SleepMsStep {
    #[serde(alias = "ms")]
    pub duration_ms: u64,
}

#[derive(Debug, Clone, Serialize, Deserialize)]
#[serde(rename_all = "camelCase")]
pub struct PerpOrder {
    pub coin: String,
    #[serde(default)]
    pub tif: PerpTif,
    pub side: OrderSide,
    pub sz: f64,
    #[serde(default)]
    pub reduce_only: bool,
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub builder_code: Option<String>,
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub cloid: Option<String>,
    #[serde(default)]
    pub trigger: Option<OrderTrigger>,
    #[serde(deserialize_with = "deserialize_order_price")]
    pub px: OrderPrice,
}

impl PerpOrder {
    pub fn is_buy(&self) -> bool {
        matches!(self.side, OrderSide::Buy)
    }
}

#[derive(Debug, Clone, Copy, Serialize, Deserialize, Default)]
#[serde(rename_all = "UPPERCASE")]
pub enum PerpTif {
    Alo,
    #[default]
    Gtc,
    Ioc,
}

impl PerpTif {
    pub fn as_sdk_str(&self) -> &'static str {
        match self {
            PerpTif::Alo => "Alo",
            PerpTif::Gtc => "Gtc",
            PerpTif::Ioc => "Ioc",
        }
    }
}

#[derive(Debug, Clone, Copy)]
pub enum OrderSide {
    Buy,
    Sell,
}

impl OrderSide {
    pub fn as_bool(&self) -> bool {
        matches!(self, OrderSide::Buy)
    }
}

impl Serialize for OrderSide {
    fn serialize<S>(&self, serializer: S) -> Result<S::Ok, S::Error>
    where
        S: Serializer,
    {
        match self {
            OrderSide::Buy => serializer.serialize_str("buy"),
            OrderSide::Sell => serializer.serialize_str("sell"),
        }
    }
}

impl<'de> Deserialize<'de> for OrderSide {
    fn deserialize<D>(deserializer: D) -> Result<Self, D::Error>
    where
        D: Deserializer<'de>,
    {
        let value = String::deserialize(deserializer)?;
        match value.to_ascii_lowercase().as_str() {
            "buy" => Ok(OrderSide::Buy),
            "sell" => Ok(OrderSide::Sell),
            other => Err(de::Error::custom(format!("invalid side '{other}'"))),
        }
    }
}

#[derive(Debug, Clone, Serialize, Deserialize)]
#[serde(tag = "kind", rename_all = "camelCase")]
pub enum OrderTrigger {
    None,
    Tp { px: OrderPrice },
    Sl { px: OrderPrice },
}

#[derive(Debug, Clone, Serialize)]
pub enum OrderPrice {
    Absolute(f64),
    MidPercent { offset_pct: f64 },
}

impl OrderPrice {
    pub fn resolve_with_mid(&self, mid: f64) -> f64 {
        match self {
            OrderPrice::Absolute(px) => *px,
            OrderPrice::MidPercent { offset_pct } => {
                let factor = 1.0 + offset_pct / 100.0;
                mid * factor
            }
        }
    }
}

fn deserialize_order_price<'de, D>(deserializer: D) -> Result<OrderPrice, D::Error>
where
    D: Deserializer<'de>,
{
    struct PriceVisitor;
    impl<'de> de::Visitor<'de> for PriceVisitor {
        type Value = OrderPrice;

        fn expecting(&self, formatter: &mut std::fmt::Formatter) -> std::fmt::Result {
            formatter.write_str("a number or a string of the form 'mid±X%'")
        }

        fn visit_f64<E>(self, value: f64) -> Result<Self::Value, E>
        where
            E: de::Error,
        {
            Ok(OrderPrice::Absolute(value))
        }

        fn visit_i64<E>(self, value: i64) -> Result<Self::Value, E>
        where
            E: de::Error,
        {
            self.visit_f64(value as f64)
        }

        fn visit_u64<E>(self, value: u64) -> Result<Self::Value, E>
        where
            E: de::Error,
        {
            self.visit_f64(value as f64)
        }

        fn visit_str<E>(self, v: &str) -> Result<Self::Value, E>
        where
            E: de::Error,
        {
            let trimmed = v.trim();
            if let Some(rest) = trimmed.strip_prefix("mid") {
                let rest = rest.trim();
                let (sign, magnitude) = if let Some(v) = rest.strip_prefix('+') {
                    (1.0_f64, v)
                } else if let Some(v) = rest.strip_prefix('-') {
                    (-1.0_f64, v)
                } else {
                    return Err(E::custom("expected '+' or '-' after 'mid'"));
                };
                let magnitude = magnitude.trim_end_matches('%').trim();
                let pct = magnitude
                    .parse::<f64>()
                    .map_err(|_| E::custom("invalid mid% offset"))?;
                Ok(OrderPrice::MidPercent {
                    offset_pct: sign * pct,
                })
            } else {
                let value = trimmed
                    .parse::<f64>()
                    .map_err(|_| E::custom("invalid absolute price"))?;
                Ok(OrderPrice::Absolute(value))
            }
        }
    }

    deserializer.deserialize_any(PriceVisitor)
}

impl<'de> Deserialize<'de> for OrderPrice {
    fn deserialize<D>(deserializer: D) -> Result<Self, D::Error>
    where
        D: Deserializer<'de>,
    {
        deserialize_order_price(deserializer)
    }
}

/// Loads a plan from a JSON file or JSONL specification.
pub fn load_plan_from_spec(spec: &str) -> Result<Plan> {
    let (path, selector) = split_spec(spec)?;
    let plan_source = if let Some(index) = selector {
        read_jsonl_entry(&path, index)?
    } else {
        std::fs::read_to_string(&path)
            .with_context(|| format!("failed to read plan file {}", path.display()))?
    };

    let plan: Plan = serde_json::from_str(&plan_source)
        .with_context(|| format!("failed to deserialize plan from {}", path.display()))?;
    Ok(plan)
}

fn read_jsonl_entry(path: &Path, index: usize) -> Result<String> {
    let file = File::open(path)
        .with_context(|| format!("failed to open plan jsonl {}", path.display()))?;
    let reader = BufReader::new(file);
    let mut line = String::new();
    for (idx, result) in reader.lines().enumerate() {
        let idx = idx + 1; // 1-based for humans
        let content =
            result.with_context(|| format!("failed to read line {idx} from {}", path.display()))?;
        if idx == index {
            line = content;
            break;
        }
    }

    if line.is_empty() {
        return Err(anyhow!("line {} not found in {}", index, path.display()));
    }
    Ok(line)
}

fn split_spec(spec: &str) -> Result<(PathBuf, Option<usize>)> {
    let mut parts = spec.rsplitn(2, ':');
    let trailing = parts.next().unwrap_or(spec);
    if let Some(prefix) = parts.next() {
        if let Ok(index) = usize::from_str(trailing) {
            return Ok((PathBuf::from(prefix), Some(index)));
        }
    }
    Ok((PathBuf::from(spec), None))
}

===== crates/hl-common/src/time.rs =====
use chrono::Utc;

/// Returns the current unix timestamp in milliseconds.
pub fn timestamp_ms() -> i64 {
    Utc::now().timestamp_millis()
}

/// Returns the floor of the timestamp to the given window size in milliseconds.
pub fn window_start_ms(ts_ms: i64, window_ms: i64) -> i64 {
    if window_ms <= 0 {
        return ts_ms;
    }
    (ts_ms / window_ms) * window_ms
}

===== crates/hl-common/src/lib.rs =====
pub mod artifacts;
pub mod plan;
pub mod time;

pub use artifacts::{ActionLogRecord, RoutedOrderRecord, RunArtifacts};
pub use plan::{
    load_plan_from_spec, ActionStep, CancelScope, OrderPrice, OrderSide, PerpOrder, Plan,
};
pub use time::{timestamp_ms, window_start_ms};

